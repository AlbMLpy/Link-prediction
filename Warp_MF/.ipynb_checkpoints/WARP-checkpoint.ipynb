{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.autograd import Variable, Function\n",
    "from torch.nn.parameter import Parameter\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy.linalg import solve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.datasets import fetch_movielens\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!curl -O http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip ml-100k.zip\n",
    "!cd ml-100k/\n",
    "!rm -r ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('ml-100k/u.data', sep='\\t', names=names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "ratings = np.zeros((n_users, n_items))\n",
    "for row in df.itertuples():\n",
    "    ratings[row[1]-1, row[2]-1] = 1.0#row[3]\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 items\n",
      "Sparsity:  6.3%\n"
     ]
    }
   ],
   "source": [
    "print(str(n_users) + ' users')\n",
    "print(str(n_items) + ' items')\n",
    "sparsity = float(len(ratings.nonzero()[0]))\n",
    "sparsity /= (ratings.shape[0] * ratings.shape[1])\n",
    "sparsity *= 100\n",
    "print('Sparsity: {:4.1f}%'.format(sparsity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratings, size=1):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], \n",
    "                                        size=size, \n",
    "                                        replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "        \n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(ratings, size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make 1000 test items for HR@N:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_test(train_data, test_data):\n",
    "    nonzero_col_idx = test_data.argmax(axis=1)\n",
    "    n_users = train_data.shape[0]\n",
    "    dt = dict()\n",
    "    for user in range(n_users):\n",
    "        row = train_data[user]\n",
    "        mask1 = row.argsort()[::-1]\n",
    "        mask2 = row[mask1] < 1.0\n",
    "        list_idx = list(mask1[mask2])\n",
    "        list_idx.remove(nonzero_col_idx[user])\n",
    "        list_idx = list_idx[:999]\n",
    "        list_idx.append(nonzero_col_idx[user])\n",
    "        dt[user] = np.array(list_idx)\n",
    "    return dt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = dict_test(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create indices/data Dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLens100k(Dataset):\n",
    "    def __init__(self, train_data):\n",
    "        rows, cols = train_data.nonzero()\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.data = train_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.rows[idx], self.cols[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dt = MovieLens100k(train_data)\n",
    "test_dt = MovieLens100k(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dt, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dt, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HR function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr(test_data, test_dict, rating, hm=10):\n",
    "    \n",
    "    test_indices = test_data.nonzero()[1]\n",
    "    total = test_data.shape[0]\n",
    "    hit = 0.0\n",
    "    for i in np.arange(total):\n",
    "        check_indices = np.argsort(rating[i][test_dict[i]])[::-1][:hm]\n",
    "        if test_indices[i] in set(test_dict[i][check_indices]):\n",
    "            hit += 1.0\n",
    "    return hit / total    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightFM WARP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and train the model\n",
    "model = LightFM(\n",
    "    no_components=50,\n",
    "    k=5,\n",
    "    n=10,\n",
    "    learning_schedule='adagrad',\n",
    "    loss='warp',\n",
    "    learning_rate=0.005,\n",
    "    rho=0.95,\n",
    "    epsilon=1e-06,\n",
    "    item_alpha=0.5,\n",
    "    user_alpha=0.3,\n",
    "    max_sampled=15,\n",
    "    random_state=13,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 200/200 [00:36<00:00,  5.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7fdb586e1dd0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(csr_matrix(train_data), epochs=200, num_threads=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007529163"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the trained model\n",
    "test_precision = precision_at_k(model, csr_matrix(test_data), k=10)\n",
    "test_precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ub, wu = model.get_user_representations()\n",
    "ib, wi = model.get_item_representations()\n",
    "w = (wu @ wi.T) + ub.T[:, np.newaxis] + ib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.20082015, -0.6056121 , -0.7084708 , ..., -1.0344007 ,\n",
       "        -1.0372866 , -1.0342679 ],\n",
       "       [ 0.22518703, -0.179605  , -0.2824638 , ..., -0.60839343,\n",
       "        -0.6112797 , -0.60826087],\n",
       "       [ 0.2508787 , -0.15391332, -0.25677198, ..., -0.582705  ,\n",
       "        -0.58558756, -0.582569  ],\n",
       "       ...,\n",
       "       [ 0.38088986, -0.02390292, -0.12676187, ..., -0.4526954 ,\n",
       "        -0.4555778 , -0.45255893],\n",
       "       [ 0.17626303, -0.22852907, -0.33138782, ..., -0.6573178 ,\n",
       "        -0.6602039 , -0.6571849 ],\n",
       "       [-0.02512944, -0.4299214 , -0.53278023, ..., -0.85871124,\n",
       "        -0.8615961 , -0.85857725]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14952279957582185"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr(test_data, test_dict, w, hm=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch WARP:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define WARP Loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WARP(Function): \n",
    "    '''\n",
    "    autograd function of WARP loss\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, target, max_num_trials=None):\n",
    "        \n",
    "        batch_size = target.size()[0]\n",
    "        if max_num_trials is None: \n",
    "            max_num_trials = target.size()[1] - 1\n",
    "        \n",
    "        positive_indices = torch.zeros(input.size())\n",
    "        negative_indices = torch.zeros(input.size())\n",
    "        L = torch.zeros(input.size()[0])\n",
    "        \n",
    "        all_labels_idx = np.arange(target.size()[1])\n",
    "        \n",
    "        Y = float(target.size()[1])\n",
    "        J = torch.nonzero(target)\n",
    "        \n",
    "        for i in range(batch_size): \n",
    "            \n",
    "            msk = np.ones(target.size()[1], dtype = bool)\n",
    "            \n",
    "            # For i user in batch choose ONE item!\n",
    "            msk_J = J[:, 0] == i\n",
    "            indice = np.random.choice(np.arange(J[msk_J].shape[0]), 1)\n",
    "            J[msk_J][indice].squeeze()[1]\n",
    "            \n",
    "            # Find the positive label for this example\n",
    "            j = J[msk_J][indice].squeeze()[1]\n",
    "            positive_indices[i, j] = 1\n",
    "            msk[j] = False\n",
    "            \n",
    "            # initialize the sample_score_margin\n",
    "            sample_score_margin = -1\n",
    "            num_trials = 0\n",
    "            \n",
    "            neg_labels_idx = all_labels_idx[msk]\n",
    "\n",
    "            while ((sample_score_margin < 0) and (num_trials < max_num_trials)):\n",
    "                 \n",
    "                #randomly sample a negative label\n",
    "                neg_idx = np.random.choice(neg_labels_idx, 1)[0]\n",
    "                msk[neg_idx] = False\n",
    "                neg_labels_idx = all_labels_idx[msk]\n",
    "                \n",
    "                num_trials += 1\n",
    "                # calculate the score margin \n",
    "                sample_score_margin = 1 + input[i, neg_idx] - input[i, j] \n",
    "            \n",
    "            if sample_score_margin < 0:\n",
    "                # checks if no violating examples have been found \n",
    "                continue\n",
    "            else: \n",
    "                loss_weight = np.log(np.floor((Y-1)/(num_trials)))\n",
    "                L[i] = loss_weight\n",
    "                negative_indices[i, neg_idx] = 1\n",
    "                \n",
    "        loss = L * (1-torch.sum(positive_indices*input, dim = 1) + torch.sum(negative_indices*input, dim = 1))\n",
    "        \n",
    "        ctx.save_for_backward(input, target)\n",
    "        ctx.L = L\n",
    "        ctx.positive_indices = positive_indices\n",
    "        ctx.negative_indices = negative_indices\n",
    "        \n",
    "        return torch.sum(loss , dim = 0, keepdim = True)\n",
    "\n",
    "    # This function has only a single output, so it gets only one gradient \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, target = ctx.saved_variables\n",
    "        L = Variable(torch.unsqueeze(ctx.L, 1), requires_grad = False)\n",
    "\n",
    "        positive_indices = Variable(ctx.positive_indices, requires_grad = False) \n",
    "        negative_indices = Variable(ctx.negative_indices, requires_grad = False)\n",
    "        grad_input = grad_output * L * (negative_indices - positive_indices)\n",
    "\n",
    "        return grad_input, None, None    \n",
    "\n",
    "      \n",
    "class WARPLoss(nn.Module): \n",
    "    def __init__(self, max_num_trials = None): \n",
    "        super(WARPLoss, self).__init__()\n",
    "        self.max_num_trials = max_num_trials\n",
    "        \n",
    "    def forward(self, input, target): \n",
    "        return WARP.apply(input, target, self.max_num_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class MF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super(MF, self).__init__()\n",
    "        \n",
    "        self.user_factors = Parameter(torch.randn(n_users, n_factors))\n",
    "        self.item_factors = Parameter(torch.randn(n_items, n_factors))\n",
    "        self.user_biases = Parameter(torch.randn(n_users, 1))\n",
    "        self.item_biases = Parameter(torch.randn(n_items, 1))\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        pred = (self.user_biases[user] + self.item_biases[item]).squeeze()\n",
    "        pred += (self.user_factors[user] * self.item_factors[item]).sum(dim=-1).squeeze()\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF()\n"
     ]
    }
   ],
   "source": [
    "n_factors = 50\n",
    "model = MF(n_users, n_items, n_factors).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=5e-3, weight_decay=1e0)#lr=5e-3 weight_decay=1e-2\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def train(train_data, model, loss_fn, optimizer):\n",
    "    \n",
    "    rows, cols = train_data.nonzero()\n",
    "    p = np.random.permutation(len(rows))\n",
    "    rows, cols = rows[p], cols[p]\n",
    "\n",
    "    for row, col in zip(*(rows, cols)):\n",
    "\n",
    "        # Turn data into tensors\n",
    "        rating = torch.FloatTensor([train_data[row, col]]).squeeze()\n",
    "        row = torch.LongTensor([row])\n",
    "        cols = torch.LongTensor([col])\n",
    "        \n",
    "        # Compute prediction error\n",
    "        prediction = model(row, col)\n",
    "        loss = loss_fn(prediction, rating)\n",
    "\n",
    "        # Set gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(dataloader, model, loss_fn, optimizer):\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (rows, cols) in enumerate(dataloader):\n",
    "        rows, cols = rows.to(device), cols.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        rating = torch.FloatTensor([dataloader.dataset.data[rows, cols]]).squeeze()\n",
    "        prediction = model(rows, cols)\n",
    "        loss = loss_fn(prediction, rating)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 500 == 0:\n",
    "            loss, current = loss.item(), batch * len(rows)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "    train(train_data, model, loss_fn, optimizer)\n",
    "    #test(test_data, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 44.113716  [    0/99057]\n",
      "loss: 1.014953  [32000/99057]\n",
      "loss: 0.981560  [64000/99057]\n",
      "loss: 0.985816  [96000/99057]\n",
      "\n",
      "Metric: HR@10 = 0.1442;\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.985588  [    0/99057]\n",
      "loss: 0.984940  [32000/99057]\n",
      "loss: 0.984455  [64000/99057]\n",
      "loss: 0.985557  [96000/99057]\n",
      "\n",
      "Metric: HR@10 = 0.1421;\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.985828  [    0/99057]\n",
      "loss: 0.985254  [32000/99057]\n",
      "loss: 0.986603  [64000/99057]\n",
      "loss: 0.984555  [96000/99057]\n",
      "\n",
      "Metric: HR@10 = 0.1453;\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.985377  [    0/99057]\n",
      "loss: 0.985700  [32000/99057]\n",
      "loss: 0.984700  [64000/99057]\n",
      "loss: 0.987007  [96000/99057]\n",
      "\n",
      "Metric: HR@10 = 0.1421;\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.986670  [    0/99057]\n",
      "loss: 0.986137  [32000/99057]\n",
      "loss: 0.986028  [64000/99057]\n",
      "loss: 0.986588  [96000/99057]\n",
      "\n",
      "Metric: HR@10 = 0.1463;\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "    train_batch(train_dataloader, model, loss_fn, optimizer)\n",
    "    W = model.user_factors.mm(model.item_factors.T).detach().numpy()\n",
    "    ub = model.user_biases.detach().numpy()\n",
    "    ib = model.item_biases.detach().numpy()\n",
    "    w = W + ub + ib.T\n",
    "    print(f\"\\nMetric: HR@10 = {hr(test_data, test_dict, w, hm=10):.4f};\\n\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = model.user_factors.mm(model.item_factors.T).detach().numpy()\n",
    "ub = model.user_biases.detach().numpy()\n",
    "ib = model.item_biases.detach().numpy()\n",
    "w = W + ub + ib.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14634146341463414"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr(test_data, test_dict, w, hm=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WARP model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class MFWARP(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super(MFWARP, self).__init__()\n",
    "        \n",
    "        self.user_factors = Parameter(torch.randn(n_users, n_factors))\n",
    "        self.item_factors = Parameter(torch.randn(n_items, n_factors))\n",
    "        self.user_biases = Parameter(torch.randn(n_users, 1))\n",
    "        self.item_biases = Parameter(torch.randn(n_items, 1))\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        pred = (self.user_biases[user] + self.item_biases[item].T)\n",
    "        pred += (self.user_factors[user] @ self.item_factors[item].T)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFWARP()\n"
     ]
    }
   ],
   "source": [
    "n_factors = 50\n",
    "model = MFWARP(n_users, n_items, n_factors).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=5e-3, weight_decay=1e-2)\n",
    "loss_fn = WARPLoss(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch_warp(train_data, model, loss_fn, optimizer, bs=64, show=True):\n",
    "    user_idx = np.arange(train_data.shape[0])\n",
    "    np.random.shuffle(user_idx)\n",
    "    batches = np.array_split(user_idx, train_data.shape[0]//bs)\n",
    "    cols = torch.arange(train_data.shape[1]).to(device)\n",
    "    \n",
    "    for i, batch in enumerate(batches):\n",
    "        rows = torch.tensor(batch).to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        rating = torch.FloatTensor([train_data[rows][:, cols]]).squeeze()\n",
    "        prediction = model(rows, cols)\n",
    "        loss = loss_fn(prediction, rating)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if show and (i % 10 == 0):\n",
    "            loss, current = loss.item(), i * len(rows)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{train_data.shape[0]:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:72: DeprecationWarning: 'saved_variables' is deprecated; use 'saved_tensors'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Metric: HR@10 = 0.0074;\n",
      "Epoch 3: Metric: HR@10 = 0.0064;\n",
      "Epoch 5: Metric: HR@10 = 0.0064;\n",
      "Epoch 7: Metric: HR@10 = 0.0064;\n",
      "Epoch 9: Metric: HR@10 = 0.0074;\n",
      "Epoch 11: Metric: HR@10 = 0.0085;\n",
      "Epoch 13: Metric: HR@10 = 0.0074;\n",
      "Epoch 15: Metric: HR@10 = 0.0074;\n",
      "Epoch 17: Metric: HR@10 = 0.0074;\n",
      "Epoch 19: Metric: HR@10 = 0.0074;\n",
      "Epoch 21: Metric: HR@10 = 0.0085;\n",
      "Epoch 23: Metric: HR@10 = 0.0064;\n",
      "Epoch 25: Metric: HR@10 = 0.0085;\n",
      "Epoch 27: Metric: HR@10 = 0.0085;\n",
      "Epoch 29: Metric: HR@10 = 0.0074;\n",
      "Epoch 31: Metric: HR@10 = 0.0074;\n",
      "Epoch 33: Metric: HR@10 = 0.0085;\n",
      "Epoch 35: Metric: HR@10 = 0.0085;\n",
      "Epoch 37: Metric: HR@10 = 0.0095;\n",
      "Epoch 39: Metric: HR@10 = 0.0138;\n",
      "Epoch 41: Metric: HR@10 = 0.0127;\n",
      "Epoch 43: Metric: HR@10 = 0.0159;\n",
      "Epoch 45: Metric: HR@10 = 0.0159;\n",
      "Epoch 47: Metric: HR@10 = 0.0138;\n",
      "Epoch 49: Metric: HR@10 = 0.0191;\n",
      "Epoch 51: Metric: HR@10 = 0.0180;\n",
      "Epoch 53: Metric: HR@10 = 0.0201;\n",
      "Epoch 55: Metric: HR@10 = 0.0212;\n",
      "Epoch 57: Metric: HR@10 = 0.0255;\n",
      "Epoch 59: Metric: HR@10 = 0.0265;\n",
      "Epoch 61: Metric: HR@10 = 0.0265;\n",
      "Epoch 63: Metric: HR@10 = 0.0276;\n",
      "Epoch 65: Metric: HR@10 = 0.0297;\n",
      "Epoch 67: Metric: HR@10 = 0.0276;\n",
      "Epoch 69: Metric: HR@10 = 0.0308;\n",
      "Epoch 71: Metric: HR@10 = 0.0308;\n",
      "Epoch 73: Metric: HR@10 = 0.0286;\n",
      "Epoch 75: Metric: HR@10 = 0.0318;\n",
      "Epoch 77: Metric: HR@10 = 0.0350;\n",
      "Epoch 79: Metric: HR@10 = 0.0371;\n",
      "Epoch 81: Metric: HR@10 = 0.0414;\n",
      "Epoch 83: Metric: HR@10 = 0.0435;\n",
      "Epoch 85: Metric: HR@10 = 0.0445;\n",
      "Epoch 87: Metric: HR@10 = 0.0488;\n",
      "Epoch 89: Metric: HR@10 = 0.0467;\n",
      "Epoch 91: Metric: HR@10 = 0.0488;\n",
      "Epoch 93: Metric: HR@10 = 0.0477;\n",
      "Epoch 95: Metric: HR@10 = 0.0498;\n",
      "Epoch 97: Metric: HR@10 = 0.0498;\n",
      "Epoch 99: Metric: HR@10 = 0.0498;\n",
      "Epoch 101: Metric: HR@10 = 0.0541;\n",
      "Epoch 103: Metric: HR@10 = 0.0594;\n",
      "Epoch 105: Metric: HR@10 = 0.0604;\n",
      "Epoch 107: Metric: HR@10 = 0.0583;\n",
      "Epoch 109: Metric: HR@10 = 0.0604;\n",
      "Epoch 111: Metric: HR@10 = 0.0583;\n",
      "Epoch 113: Metric: HR@10 = 0.0594;\n",
      "Epoch 115: Metric: HR@10 = 0.0615;\n",
      "Epoch 117: Metric: HR@10 = 0.0636;\n",
      "Epoch 119: Metric: HR@10 = 0.0657;\n",
      "Epoch 121: Metric: HR@10 = 0.0668;\n",
      "Epoch 123: Metric: HR@10 = 0.0657;\n",
      "Epoch 125: Metric: HR@10 = 0.0710;\n",
      "Epoch 127: Metric: HR@10 = 0.0710;\n",
      "Epoch 129: Metric: HR@10 = 0.0774;\n",
      "Epoch 131: Metric: HR@10 = 0.0774;\n",
      "Epoch 133: Metric: HR@10 = 0.0795;\n",
      "Epoch 135: Metric: HR@10 = 0.0806;\n",
      "Epoch 137: Metric: HR@10 = 0.0795;\n",
      "Epoch 139: Metric: HR@10 = 0.0870;\n",
      "Epoch 141: Metric: HR@10 = 0.0806;\n",
      "Epoch 143: Metric: HR@10 = 0.0827;\n",
      "Epoch 145: Metric: HR@10 = 0.0870;\n",
      "Epoch 147: Metric: HR@10 = 0.0838;\n",
      "Epoch 149: Metric: HR@10 = 0.0923;\n",
      "Epoch 151: Metric: HR@10 = 0.0880;\n",
      "Epoch 153: Metric: HR@10 = 0.0912;\n",
      "Epoch 155: Metric: HR@10 = 0.0859;\n",
      "Epoch 157: Metric: HR@10 = 0.0870;\n",
      "Epoch 159: Metric: HR@10 = 0.0901;\n",
      "Epoch 161: Metric: HR@10 = 0.0933;\n",
      "Epoch 163: Metric: HR@10 = 0.0912;\n",
      "Epoch 165: Metric: HR@10 = 0.0944;\n",
      "Epoch 167: Metric: HR@10 = 0.0986;\n",
      "Epoch 169: Metric: HR@10 = 0.1029;\n",
      "Epoch 171: Metric: HR@10 = 0.1029;\n",
      "Epoch 173: Metric: HR@10 = 0.0923;\n",
      "Epoch 175: Metric: HR@10 = 0.0923;\n",
      "Epoch 177: Metric: HR@10 = 0.0986;\n",
      "Epoch 179: Metric: HR@10 = 0.1007;\n",
      "Epoch 181: Metric: HR@10 = 0.1018;\n",
      "Epoch 183: Metric: HR@10 = 0.1018;\n",
      "Epoch 185: Metric: HR@10 = 0.1113;\n",
      "Epoch 187: Metric: HR@10 = 0.1039;\n",
      "Epoch 189: Metric: HR@10 = 0.1113;\n",
      "Epoch 191: Metric: HR@10 = 0.1156;\n",
      "Epoch 193: Metric: HR@10 = 0.1082;\n",
      "Epoch 195: Metric: HR@10 = 0.1071;\n",
      "Epoch 197: Metric: HR@10 = 0.1113;\n",
      "Epoch 199: Metric: HR@10 = 0.1113;\n",
      "Epoch 201: Metric: HR@10 = 0.1166;\n",
      "Epoch 203: Metric: HR@10 = 0.1156;\n",
      "Epoch 205: Metric: HR@10 = 0.1177;\n",
      "Epoch 207: Metric: HR@10 = 0.1166;\n",
      "Epoch 209: Metric: HR@10 = 0.1209;\n",
      "Epoch 211: Metric: HR@10 = 0.1283;\n",
      "Epoch 213: Metric: HR@10 = 0.1230;\n",
      "Epoch 215: Metric: HR@10 = 0.1220;\n",
      "Epoch 217: Metric: HR@10 = 0.1230;\n",
      "Epoch 219: Metric: HR@10 = 0.1304;\n",
      "Epoch 221: Metric: HR@10 = 0.1283;\n",
      "Epoch 223: Metric: HR@10 = 0.1336;\n",
      "Epoch 225: Metric: HR@10 = 0.1315;\n",
      "Epoch 227: Metric: HR@10 = 0.1304;\n",
      "Epoch 229: Metric: HR@10 = 0.1283;\n",
      "Epoch 231: Metric: HR@10 = 0.1262;\n",
      "Epoch 233: Metric: HR@10 = 0.1241;\n",
      "Epoch 235: Metric: HR@10 = 0.1220;\n",
      "Epoch 237: Metric: HR@10 = 0.1209;\n",
      "Epoch 239: Metric: HR@10 = 0.1251;\n",
      "Epoch 241: Metric: HR@10 = 0.1273;\n",
      "Epoch 243: Metric: HR@10 = 0.1273;\n",
      "Epoch 245: Metric: HR@10 = 0.1273;\n",
      "Epoch 247: Metric: HR@10 = 0.1315;\n",
      "Epoch 249: Metric: HR@10 = 0.1347;\n",
      "Epoch 251: Metric: HR@10 = 0.1326;\n",
      "Epoch 253: Metric: HR@10 = 0.1336;\n",
      "Epoch 255: Metric: HR@10 = 0.1368;\n",
      "Epoch 257: Metric: HR@10 = 0.1400;\n",
      "Epoch 259: Metric: HR@10 = 0.1410;\n",
      "Epoch 261: Metric: HR@10 = 0.1368;\n",
      "Epoch 263: Metric: HR@10 = 0.1368;\n",
      "Epoch 265: Metric: HR@10 = 0.1442;\n",
      "Epoch 267: Metric: HR@10 = 0.1432;\n",
      "Epoch 269: Metric: HR@10 = 0.1442;\n",
      "Epoch 271: Metric: HR@10 = 0.1474;\n",
      "Epoch 273: Metric: HR@10 = 0.1474;\n",
      "Epoch 275: Metric: HR@10 = 0.1389;\n",
      "Epoch 277: Metric: HR@10 = 0.1400;\n",
      "Epoch 279: Metric: HR@10 = 0.1516;\n",
      "Epoch 281: Metric: HR@10 = 0.1516;\n",
      "Epoch 283: Metric: HR@10 = 0.1463;\n",
      "Epoch 285: Metric: HR@10 = 0.1421;\n",
      "Epoch 287: Metric: HR@10 = 0.1495;\n",
      "Epoch 289: Metric: HR@10 = 0.1442;\n",
      "Epoch 291: Metric: HR@10 = 0.1442;\n",
      "Epoch 293: Metric: HR@10 = 0.1495;\n",
      "Epoch 295: Metric: HR@10 = 0.1485;\n",
      "Epoch 297: Metric: HR@10 = 0.1495;\n",
      "Epoch 299: Metric: HR@10 = 0.1410;\n",
      "Epoch 301: Metric: HR@10 = 0.1389;\n",
      "Epoch 303: Metric: HR@10 = 0.1495;\n",
      "Epoch 305: Metric: HR@10 = 0.1527;\n",
      "Epoch 307: Metric: HR@10 = 0.1622;\n",
      "Epoch 309: Metric: HR@10 = 0.1622;\n",
      "Epoch 311: Metric: HR@10 = 0.1654;\n",
      "Epoch 313: Metric: HR@10 = 0.1633;\n",
      "Epoch 315: Metric: HR@10 = 0.1569;\n",
      "Epoch 317: Metric: HR@10 = 0.1580;\n",
      "Epoch 319: Metric: HR@10 = 0.1559;\n",
      "Epoch 321: Metric: HR@10 = 0.1548;\n",
      "Epoch 323: Metric: HR@10 = 0.1559;\n",
      "Epoch 325: Metric: HR@10 = 0.1516;\n",
      "Epoch 327: Metric: HR@10 = 0.1644;\n",
      "Epoch 329: Metric: HR@10 = 0.1644;\n",
      "Epoch 331: Metric: HR@10 = 0.1644;\n",
      "Epoch 333: Metric: HR@10 = 0.1601;\n",
      "Epoch 335: Metric: HR@10 = 0.1633;\n",
      "Epoch 337: Metric: HR@10 = 0.1633;\n",
      "Epoch 339: Metric: HR@10 = 0.1654;\n",
      "Epoch 341: Metric: HR@10 = 0.1654;\n",
      "Epoch 343: Metric: HR@10 = 0.1686;\n",
      "Epoch 345: Metric: HR@10 = 0.1750;\n",
      "Epoch 347: Metric: HR@10 = 0.1739;\n",
      "Epoch 349: Metric: HR@10 = 0.1803;\n",
      "Epoch 351: Metric: HR@10 = 0.1792;\n",
      "Epoch 353: Metric: HR@10 = 0.1792;\n",
      "Epoch 355: Metric: HR@10 = 0.1782;\n",
      "Epoch 357: Metric: HR@10 = 0.1739;\n",
      "Epoch 359: Metric: HR@10 = 0.1782;\n",
      "Epoch 361: Metric: HR@10 = 0.1739;\n",
      "Epoch 363: Metric: HR@10 = 0.1771;\n",
      "Epoch 365: Metric: HR@10 = 0.1718;\n",
      "Epoch 367: Metric: HR@10 = 0.1697;\n",
      "Epoch 369: Metric: HR@10 = 0.1760;\n",
      "Epoch 371: Metric: HR@10 = 0.1697;\n",
      "Epoch 373: Metric: HR@10 = 0.1739;\n",
      "Epoch 375: Metric: HR@10 = 0.1729;\n",
      "Epoch 377: Metric: HR@10 = 0.1771;\n",
      "Epoch 379: Metric: HR@10 = 0.1792;\n",
      "Epoch 381: Metric: HR@10 = 0.1760;\n",
      "Epoch 383: Metric: HR@10 = 0.1718;\n",
      "Epoch 385: Metric: HR@10 = 0.1803;\n",
      "Epoch 387: Metric: HR@10 = 0.1792;\n",
      "Epoch 389: Metric: HR@10 = 0.1813;\n",
      "Epoch 391: Metric: HR@10 = 0.1813;\n",
      "Epoch 393: Metric: HR@10 = 0.1782;\n",
      "Epoch 395: Metric: HR@10 = 0.1771;\n",
      "Epoch 397: Metric: HR@10 = 0.1803;\n",
      "Epoch 399: Metric: HR@10 = 0.1835;\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 400\n",
    "for epoch in range(epochs):\n",
    "    if epoch%2 == 0:\n",
    "        #print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "        train_batch_warp(train_data, model, loss_fn, optimizer, 10, show=False)\n",
    "        W = model.user_factors.mm(model.item_factors.T).detach().numpy()\n",
    "        ub = model.user_biases.detach().numpy()\n",
    "        ib = model.item_biases.detach().numpy()\n",
    "        w = W + ub + ib.T\n",
    "        print(f\"Epoch {epoch + 1}: Metric: HR@10 = {hr(test_data, test_dict, w, hm=10):.4f};\")\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
