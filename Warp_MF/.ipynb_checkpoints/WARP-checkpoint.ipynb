{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.autograd import Variable, Function\n",
    "from torch.nn.parameter import Parameter\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy.linalg import solve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.datasets import fetch_movielens\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!curl -O http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip ml-100k.zip\n",
    "!cd ml-100k/\n",
    "!rm -r ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('ml-100k/u.data', sep='\\t', names=names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "ratings = np.zeros((n_users, n_items))\n",
    "for row in df.itertuples():\n",
    "    ratings[row[1]-1, row[2]-1] = 1.0#row[3]\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 items\n",
      "Sparsity:  6.3%\n"
     ]
    }
   ],
   "source": [
    "print(str(n_users) + ' users')\n",
    "print(str(n_items) + ' items')\n",
    "sparsity = float(len(ratings.nonzero()[0]))\n",
    "sparsity /= (ratings.shape[0] * ratings.shape[1])\n",
    "sparsity *= 100\n",
    "print('Sparsity: {:4.1f}%'.format(sparsity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratings, size=1):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], \n",
    "                                        size=size, \n",
    "                                        replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "        \n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(ratings, size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make 1000 test items for HR@N:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_test(train_data, test_data):\n",
    "    nonzero_col_idx = test_data.argmax(axis=1)\n",
    "    n_users = train_data.shape[0]\n",
    "    dt = dict()\n",
    "    for user in range(n_users):\n",
    "        row = train_data[user]\n",
    "        mask1 = row.argsort()[::-1]\n",
    "        mask2 = row[mask1] < 1.0\n",
    "        list_idx = list(mask1[mask2])\n",
    "        list_idx.remove(nonzero_col_idx[user])\n",
    "        list_idx = list_idx[:999]\n",
    "        list_idx.append(nonzero_col_idx[user])\n",
    "        dt[user] = np.array(list_idx)\n",
    "    return dt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = dict_test(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create indices/data Dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLens100k(Dataset):\n",
    "    def __init__(self, train_data):\n",
    "        rows, cols = train_data.nonzero()\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.data = train_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.rows[idx], self.cols[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dt = MovieLens100k(train_data)\n",
    "test_dt = MovieLens100k(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dt, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dt, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HR function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr(test_data, test_dict, rating, hm=10):\n",
    "    \n",
    "    test_indices = test_data.nonzero()[1]\n",
    "    total = test_data.shape[0]\n",
    "    hit = 0.0\n",
    "    for i in np.arange(total):\n",
    "        check_indices = np.argsort(rating[i][test_dict[i]])[::-1][:hm]\n",
    "        if test_indices[i] in set(test_dict[i][check_indices]):\n",
    "            hit += 1.0\n",
    "    return hit / total    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightFM WARP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and train the model\n",
    "model = LightFM(\n",
    "    no_components=50,\n",
    "    k=5,\n",
    "    n=10,\n",
    "    learning_schedule='adagrad',\n",
    "    loss='warp',\n",
    "    learning_rate=0.005,\n",
    "    rho=0.95,\n",
    "    epsilon=1e-06,\n",
    "    item_alpha=0.5,\n",
    "    user_alpha=0.3,\n",
    "    max_sampled=15,\n",
    "    random_state=13,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100% 200/200 [00:27<00:00,  7.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f626e81a310>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(csr_matrix(train_data), epochs=200, num_threads=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0077412515"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the trained model\n",
    "test_precision = precision_at_k(model, csr_matrix(test_data), k=10)\n",
    "test_precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ub, wu = model.get_user_representations()\n",
    "ib, wi = model.get_item_representations()\n",
    "w = (wu @ wi.T) + ub.T[:, np.newaxis] + ib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.19956619, -0.55794764, -0.65266085, ..., -0.94264656,\n",
       "        -0.94515145, -0.94099104],\n",
       "       [ 0.19057557, -0.16780505, -0.26251835, ..., -0.5525039 ,\n",
       "        -0.5550087 , -0.55080813],\n",
       "       [ 0.21373567, -0.14464542, -0.23935899, ..., -0.5293446 ,\n",
       "        -0.5318497 , -0.52764857],\n",
       "       ...,\n",
       "       [ 0.33281553, -0.02556533, -0.12027884, ..., -0.41026437,\n",
       "        -0.4127695 , -0.4085665 ],\n",
       "       [ 0.14487636, -0.21350452, -0.30821803, ..., -0.5982036 ,\n",
       "        -0.6007087 , -0.59651136],\n",
       "       [-0.03850049, -0.39688137, -0.49159482, ..., -0.7815803 ,\n",
       "        -0.78408533, -0.7798884 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12301166489925769"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr(test_data, test_dict, w, hm=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch WARP:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define WARP Loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WARP(Function): \n",
    "    '''\n",
    "    autograd function of WARP loss\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, target, max_num_trials=None):\n",
    "        \n",
    "        batch_size = target.size()[0]\n",
    "        if max_num_trials is None: \n",
    "            max_num_trials = target.size()[1] - 1\n",
    "        \n",
    "        positive_indices = torch.zeros(input.size(), device=device)\n",
    "        negative_indices = torch.zeros(input.size(), device=device)\n",
    "        L = torch.zeros(input.size()[0], device=device)\n",
    "        \n",
    "        all_labels_idx = np.arange(target.size()[1])\n",
    "        \n",
    "        Y = float(target.size()[1])\n",
    "        J = torch.nonzero(target)\n",
    "        \n",
    "        for i in range(batch_size): \n",
    "            \n",
    "            msk = np.ones(target.size()[1], dtype = bool)\n",
    "            \n",
    "            # For i user in batch choose ONE item!\n",
    "            msk_J = J[:, 0] == i\n",
    "            indice = np.random.choice(np.arange(J[msk_J].shape[0]), 1)\n",
    "            J[msk_J][indice].squeeze()[1]\n",
    "            \n",
    "            # Find the positive label for this example\n",
    "            j = J[msk_J][indice].squeeze()[1]\n",
    "            positive_indices[i, j] = 1\n",
    "            msk[j] = False\n",
    "            \n",
    "            # initialize the sample_score_margin\n",
    "            sample_score_margin = -1\n",
    "            num_trials = 0\n",
    "            \n",
    "            neg_labels_idx = all_labels_idx[msk]\n",
    "\n",
    "            while ((sample_score_margin < 0) and (num_trials < max_num_trials)):\n",
    "                 \n",
    "                #randomly sample a negative label\n",
    "                neg_idx = np.random.choice(neg_labels_idx, 1)[0]\n",
    "                msk[neg_idx] = False\n",
    "                neg_labels_idx = all_labels_idx[msk]\n",
    "                \n",
    "                num_trials += 1\n",
    "                # calculate the score margin \n",
    "                sample_score_margin = 1 + input[i, neg_idx] - input[i, j] \n",
    "            \n",
    "            if sample_score_margin < 0:\n",
    "                # checks if no violating examples have been found \n",
    "                continue\n",
    "            else: \n",
    "                loss_weight = np.log(np.floor((Y-1)/(num_trials)))\n",
    "                L[i] = loss_weight\n",
    "                negative_indices[i, neg_idx] = 1\n",
    "        \n",
    "        loss = L * (1-torch.sum(positive_indices*input, dim = 1) + torch.sum(negative_indices*input, dim = 1))\n",
    "        \n",
    "        ctx.save_for_backward(input, target)\n",
    "        ctx.L = L\n",
    "        ctx.positive_indices = positive_indices\n",
    "        ctx.negative_indices = negative_indices\n",
    "        \n",
    "        return torch.sum(loss , dim = 0, keepdim = True)\n",
    "\n",
    "    # This function has only a single output, so it gets only one gradient \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, target = ctx.saved_tensors\n",
    "        L = Variable(torch.unsqueeze(ctx.L, 1), requires_grad = False)\n",
    "\n",
    "        positive_indices = Variable(ctx.positive_indices, requires_grad = False) \n",
    "        negative_indices = Variable(ctx.negative_indices, requires_grad = False)\n",
    "        grad_input = grad_output * L * (negative_indices - positive_indices)\n",
    "\n",
    "        return grad_input, None, None    \n",
    "\n",
    "      \n",
    "class WARPLoss(nn.Module): \n",
    "    def __init__(self, max_num_trials = None): \n",
    "        super(WARPLoss, self).__init__()\n",
    "        self.max_num_trials = max_num_trials\n",
    "        \n",
    "    def forward(self, input, target): \n",
    "        return WARP.apply(input, target, self.max_num_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:1 device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class MF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super(MF, self).__init__()\n",
    "        \n",
    "        self.user_factors = Parameter(torch.randn(n_users, n_factors))\n",
    "        self.item_factors = Parameter(torch.randn(n_items, n_factors))\n",
    "        self.user_biases = Parameter(torch.randn(n_users, 1))\n",
    "        self.item_biases = Parameter(torch.randn(n_items, 1))\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        pred = (self.user_biases[user] + self.item_biases[item]).squeeze()\n",
    "        pred += (self.user_factors[user] * self.item_factors[item]).sum(dim=-1).squeeze()\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF()\n"
     ]
    }
   ],
   "source": [
    "n_factors = 50\n",
    "model = MF(n_users, n_items, n_factors).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=5e-3, weight_decay=1e0)#lr=5e-3 weight_decay=1e-2\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def train(train_data, model, loss_fn, optimizer):\n",
    "    \n",
    "    rows, cols = train_data.nonzero()\n",
    "    p = np.random.permutation(len(rows))\n",
    "    rows, cols = rows[p], cols[p]\n",
    "\n",
    "    for row, col in zip(*(rows, cols)):\n",
    "\n",
    "        # Turn data into tensors\n",
    "        rating = torch.FloatTensor([train_data[row, col]]).squeeze()\n",
    "        row = torch.LongTensor([row])\n",
    "        cols = torch.LongTensor([col])\n",
    "        \n",
    "        # Compute prediction error\n",
    "        prediction = model(row, col)\n",
    "        loss = loss_fn(prediction, rating)\n",
    "\n",
    "        # Set gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(dataloader, model, loss_fn, optimizer):\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (rows, cols) in enumerate(dataloader):\n",
    "        rows_c, cols_c = rows.to(device), cols.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        rating = torch.tensor([dataloader.dataset.data[rows, cols]], device=device).squeeze()\n",
    "        prediction = model(rows_c, cols_c).to(torch.float64)\n",
    "        loss = loss_fn(prediction, rating)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 500 == 0:\n",
    "            loss, current = loss.item(), batch * len(rows)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=torch.tensor(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6., dtype=torch.float64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.to(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "    train(train_data, model, loss_fn, optimizer)\n",
    "    #test(test_data, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.984897  [    0/99057]\n",
      "loss: 0.986606  [32000/99057]\n",
      "loss: 0.985060  [64000/99057]\n",
      "loss: 0.985669  [96000/99057]\n",
      "\n",
      "Metric: HR@10 = 0.1198;\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.984219  [    0/99057]\n",
      "loss: 0.984408  [32000/99057]\n",
      "loss: 0.985858  [64000/99057]\n",
      "loss: 0.985262  [96000/99057]\n",
      "\n",
      "Metric: HR@10 = 0.1220;\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.984201  [    0/99057]\n",
      "loss: 0.984978  [32000/99057]\n",
      "loss: 0.985882  [64000/99057]\n",
      "loss: 0.984860  [96000/99057]\n",
      "\n",
      "Metric: HR@10 = 0.1273;\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.983812  [    0/99057]\n",
      "loss: 0.984775  [32000/99057]\n",
      "loss: 0.984694  [64000/99057]\n",
      "loss: 0.986041  [96000/99057]\n",
      "\n",
      "Metric: HR@10 = 0.1209;\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.984359  [    0/99057]\n",
      "loss: 0.985664  [32000/99057]\n",
      "loss: 0.986980  [64000/99057]\n",
      "loss: 0.986972  [96000/99057]\n",
      "\n",
      "Metric: HR@10 = 0.1220;\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "    train_batch(train_dataloader, model, loss_fn, optimizer)\n",
    "    W = model.user_factors.mm(model.item_factors.T).cpu().detach().numpy()\n",
    "    ub = model.user_biases.cpu().detach().numpy()\n",
    "    ib = model.item_biases.cpu().detach().numpy()\n",
    "    w = W + ub + ib.T\n",
    "    print(f\"\\nMetric: HR@10 = {hr(test_data, test_dict, w, hm=10):.4f};\\n\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = model.user_factors.mm(model.item_factors.T).detach().numpy()\n",
    "ub = model.user_biases.detach().numpy()\n",
    "ib = model.item_biases.detach().numpy()\n",
    "w = W + ub + ib.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14634146341463414"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr(test_data, test_dict, w, hm=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WARP model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class MFWARP(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super(MFWARP, self).__init__()\n",
    "        \n",
    "        self.user_factors = Parameter(torch.randn(n_users, n_factors))\n",
    "        self.item_factors = Parameter(torch.randn(n_items, n_factors))\n",
    "        self.user_biases = Parameter(torch.randn(n_users, 1))\n",
    "        self.item_biases = Parameter(torch.randn(n_items, 1))\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        pred = (self.user_biases[user] + self.item_biases[item].T)\n",
    "        pred += (self.user_factors[user] @ self.item_factors[item].T)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFWARP()\n"
     ]
    }
   ],
   "source": [
    "n_factors = 50\n",
    "model = MFWARP(n_users, n_items, n_factors).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=5e-3, weight_decay=1e-2)\n",
    "loss_fn = WARPLoss(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch_warp(train_data, model, loss_fn, optimizer, bs=64, show=True):\n",
    "    user_idx = np.arange(train_data.shape[0])\n",
    "    np.random.shuffle(user_idx)\n",
    "    batches = np.array_split(user_idx, train_data.shape[0]//bs)\n",
    "    cols = torch.arange(train_data.shape[1])\n",
    "    cols_c = cols.to(device)\n",
    "    \n",
    "    for i, batch in enumerate(batches):\n",
    "        rows = torch.tensor(batch)\n",
    "        rows_c = rows.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        rating = torch.tensor([train_data[rows][:, cols]], device=device).squeeze()\n",
    "        prediction = model(rows_c, cols_c).to(torch.float64)\n",
    "        loss = loss_fn(prediction, rating)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if show and (i % 10 == 0):\n",
    "            loss, current = loss.item(), i * len(rows)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{train_data.shape[0]:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Metric: HR@10 = 0.1060;\n",
      "Epoch 21: Metric: HR@10 = 0.1241;\n",
      "Epoch 41: Metric: HR@10 = 0.1357;\n",
      "Epoch 61: Metric: HR@10 = 0.1474;\n",
      "Epoch 81: Metric: HR@10 = 0.1516;\n",
      "Epoch 101: Metric: HR@10 = 0.1527;\n",
      "Epoch 121: Metric: HR@10 = 0.1633;\n",
      "Epoch 141: Metric: HR@10 = 0.1750;\n",
      "Epoch 161: Metric: HR@10 = 0.1665;\n",
      "Epoch 181: Metric: HR@10 = 0.1718;\n",
      "Epoch 201: Metric: HR@10 = 0.2004;\n",
      "Epoch 221: Metric: HR@10 = 0.1972;\n",
      "Epoch 241: Metric: HR@10 = 0.2100;\n",
      "Epoch 261: Metric: HR@10 = 0.2004;\n",
      "Epoch 281: Metric: HR@10 = 0.1909;\n",
      "Epoch 301: Metric: HR@10 = 0.1898;\n",
      "Epoch 321: Metric: HR@10 = 0.2015;\n",
      "Epoch 341: Metric: HR@10 = 0.2110;\n",
      "Epoch 361: Metric: HR@10 = 0.2206;\n",
      "Epoch 381: Metric: HR@10 = 0.2089;\n",
      "Epoch 401: Metric: HR@10 = 0.2439;\n",
      "Epoch 421: Metric: HR@10 = 0.2397;\n",
      "Epoch 441: Metric: HR@10 = 0.2344;\n",
      "Epoch 461: Metric: HR@10 = 0.2259;\n",
      "Epoch 481: Metric: HR@10 = 0.2259;\n",
      "Epoch 501: Metric: HR@10 = 0.2333;\n",
      "Epoch 521: Metric: HR@10 = 0.2142;\n",
      "Epoch 541: Metric: HR@10 = 0.2344;\n",
      "Epoch 561: Metric: HR@10 = 0.2418;\n",
      "Epoch 581: Metric: HR@10 = 0.2333;\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 600\n",
    "for epoch in range(epochs):\n",
    "    train_batch_warp(train_data, model, loss_fn, optimizer, 64, show=False)\n",
    "    W = model.user_factors.mm(model.item_factors.T).cpu().detach().numpy()\n",
    "    ub = model.user_biases.cpu().detach().numpy()\n",
    "    ib = model.item_biases.cpu().detach().numpy()\n",
    "    w = W + ub + ib.T\n",
    "    \n",
    "    if epoch%20 == 0:   \n",
    "        print(f\"Epoch {epoch + 1}: Metric: HR@10 = {hr(test_data, test_dict, w, hm=10):.4f};\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
