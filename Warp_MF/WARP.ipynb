{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.autograd import Variable, Function\n",
    "from torch.nn.parameter import Parameter\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy.linalg import solve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.datasets import fetch_movielens\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!curl -O http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip ml-100k.zip\n",
    "!cd ml-100k/\n",
    "!rm -r ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('ml-100k/u.data', sep='\\t', names=names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "ratings = np.zeros((n_users, n_items))\n",
    "for row in df.itertuples():\n",
    "    ratings[row[1]-1, row[2]-1] = 1.0#row[3]\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 items\n",
      "Sparsity:  6.3%\n"
     ]
    }
   ],
   "source": [
    "print(str(n_users) + ' users')\n",
    "print(str(n_items) + ' items')\n",
    "sparsity = float(len(ratings.nonzero()[0]))\n",
    "sparsity /= (ratings.shape[0] * ratings.shape[1])\n",
    "sparsity *= 100\n",
    "print('Sparsity: {:4.1f}%'.format(sparsity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratings, size=1):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], \n",
    "                                        size=size, \n",
    "                                        replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "        \n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(ratings, size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make 1000 test items for HR@N:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_test(train_data, test_data):\n",
    "    nonzero_col_idx = test_data.argmax(axis=1)\n",
    "    n_users = train_data.shape[0]\n",
    "    dt = dict()\n",
    "    for user in range(n_users):\n",
    "        row = train_data[user]\n",
    "        mask1 = row.argsort()[::-1]\n",
    "        mask2 = row[mask1] < 1.0\n",
    "        list_idx = list(mask1[mask2])\n",
    "        list_idx.remove(nonzero_col_idx[user])\n",
    "        list_idx = list_idx[:999]\n",
    "        list_idx.append(nonzero_col_idx[user])\n",
    "        dt[user] = np.array(list_idx)\n",
    "    return dt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = dict_test(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create indices/data Dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLens100k(Dataset):\n",
    "    def __init__(self, train_data):\n",
    "        rows, cols = train_data.nonzero()\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.data = train_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.rows[idx], self.cols[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dt = MovieLens100k(train_data)\n",
    "test_dt = MovieLens100k(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dt, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dt, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HR function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr(test_data, test_dict, rating, hm=10):\n",
    "    \n",
    "    test_indices = test_data.nonzero()[1]\n",
    "    total = test_data.shape[0]\n",
    "    hit = 0.0\n",
    "    for i in np.arange(total):\n",
    "        check_indices = np.argsort(rating[i][test_dict[i]])[::-1][:hm]\n",
    "        if test_indices[i] in set(test_dict[i][check_indices]):\n",
    "            hit += 1.0\n",
    "    return hit / total    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightFM WARP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and train the model\n",
    "model = LightFM(\n",
    "    no_components=50,\n",
    "    k=5,\n",
    "    n=10,\n",
    "    learning_schedule='adagrad',\n",
    "    loss='warp',\n",
    "    learning_rate=0.005,\n",
    "    rho=0.95,\n",
    "    epsilon=1e-06,\n",
    "    item_alpha=0.5,\n",
    "    user_alpha=0.3,\n",
    "    max_sampled=15,\n",
    "    random_state=13,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100% 200/200 [00:25<00:00,  7.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f3d1e1edbe0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(csr_matrix(train_data), epochs=200, num_threads=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.19865036, -0.5474862 , -0.6383625 , ..., -0.9256259 ,\n",
       "        -0.9274133 , -0.924332  ],\n",
       "       [ 0.18439803, -0.16417046, -0.25517118, ..., -0.541932  ,\n",
       "        -0.5441742 , -0.5411384 ],\n",
       "       [ 0.20720148, -0.14136712, -0.23236978, ..., -0.5191307 ,\n",
       "        -0.5213729 , -0.51833516],\n",
       "       ...,\n",
       "       [ 0.32412323, -0.0244507 , -0.11545103, ..., -0.40220818,\n",
       "        -0.40445364, -0.40141708],\n",
       "       [ 0.13970917, -0.20885937, -0.29985982, ..., -0.5866214 ,\n",
       "        -0.588863  , -0.585827  ],\n",
       "       [-0.04027218, -0.38884032, -0.47984084, ..., -0.7666024 ,\n",
       "        -0.768844  , -0.765808  ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ub, wu = model.get_user_representations()\n",
    "ib, wi = model.get_item_representations()\n",
    "w = (wu @ wi.T) + ub.T[:, np.newaxis] + ib\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15270413573700956"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr(test_data, test_dict, w, hm=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch WARP:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define WARP Loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WARP(Function): \n",
    "    '''\n",
    "    autograd function of WARP loss\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, target, max_num_trials=None):\n",
    "        \n",
    "        batch_size = target.size()[0]\n",
    "        if max_num_trials is None: \n",
    "            max_num_trials = target.size()[1] - 1\n",
    "        \n",
    "        positive_indices = torch.zeros(input.size(), device=device)\n",
    "        negative_indices = torch.zeros(input.size(), device=device)\n",
    "        L = torch.zeros(input.size()[0], device=device)\n",
    "        \n",
    "        all_labels_idx = np.arange(target.size()[1])\n",
    "        \n",
    "        Y = float(target.size()[1])\n",
    "        J = torch.nonzero(target)\n",
    "        \n",
    "        for i in range(batch_size): \n",
    "            \n",
    "            msk = np.ones(target.size()[1], dtype = bool)\n",
    "            \n",
    "            # For i user in batch choose ONE item!\n",
    "            msk_J = J[:, 0] == i\n",
    "            indice = np.random.choice(np.arange(J[msk_J].shape[0]), 1)\n",
    "            J[msk_J][indice].squeeze()[1]\n",
    "            \n",
    "            # Find the positive label for this example\n",
    "            j = J[msk_J][indice].squeeze()[1]\n",
    "            positive_indices[i, j] = 1\n",
    "            msk[j] = False\n",
    "            \n",
    "            # initialize the sample_score_margin\n",
    "            sample_score_margin = -1\n",
    "            num_trials = 0\n",
    "            \n",
    "            neg_labels_idx = all_labels_idx[msk]\n",
    "\n",
    "            while ((sample_score_margin < 0) and (num_trials < max_num_trials)):\n",
    "                 \n",
    "                #randomly sample a negative label\n",
    "                neg_idx = np.random.choice(neg_labels_idx, 1)[0]\n",
    "                msk[neg_idx] = False\n",
    "                neg_labels_idx = all_labels_idx[msk]\n",
    "                \n",
    "                num_trials += 1\n",
    "                # calculate the score margin \n",
    "                sample_score_margin = 1 + input[i, neg_idx] - input[i, j] \n",
    "            \n",
    "            if sample_score_margin < 0:\n",
    "                # checks if no violating examples have been found \n",
    "                continue\n",
    "            else: \n",
    "                loss_weight = np.log(np.floor((Y-1)/(num_trials)))\n",
    "                L[i] = loss_weight\n",
    "                negative_indices[i, neg_idx] = 1\n",
    "        \n",
    "        loss = L * (1-torch.sum(positive_indices*input, dim = 1) + torch.sum(negative_indices*input, dim = 1))\n",
    "        \n",
    "        ctx.save_for_backward(input, target)\n",
    "        ctx.L = L\n",
    "        ctx.positive_indices = positive_indices\n",
    "        ctx.negative_indices = negative_indices\n",
    "        \n",
    "        return torch.sum(loss , dim = 0, keepdim = True)\n",
    "\n",
    "    # This function has only a single output, so it gets only one gradient \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, target = ctx.saved_tensors\n",
    "        L = Variable(torch.unsqueeze(ctx.L, 1), requires_grad = False)\n",
    "\n",
    "        positive_indices = Variable(ctx.positive_indices, requires_grad = False) \n",
    "        negative_indices = Variable(ctx.negative_indices, requires_grad = False)\n",
    "        grad_input = grad_output * L * (negative_indices - positive_indices)\n",
    "\n",
    "        return grad_input, None, None    \n",
    "\n",
    "      \n",
    "class WARPLoss(nn.Module): \n",
    "    def __init__(self, max_num_trials = None): \n",
    "        super(WARPLoss, self).__init__()\n",
    "        self.max_num_trials = max_num_trials\n",
    "        \n",
    "    def forward(self, input, target): \n",
    "        return WARP.apply(input, target, self.max_num_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:1 device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class MF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super(MF, self).__init__()\n",
    "        \n",
    "        self.user_factors = Parameter(torch.randn(n_users, n_factors))\n",
    "        self.item_factors = Parameter(torch.randn(n_items, n_factors))\n",
    "        self.user_biases = Parameter(torch.randn(n_users, 1))\n",
    "        self.item_biases = Parameter(torch.randn(n_items, 1))\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        pred = (self.user_biases[user] + self.item_biases[item]).squeeze()\n",
    "        pred += (self.user_factors[user] * self.item_factors[item]).sum(dim=-1).squeeze()\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF()\n"
     ]
    }
   ],
   "source": [
    "n_factors = 50\n",
    "model = MF(n_users, n_items, n_factors).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=5e-3, weight_decay=1e0)#lr=5e-3 weight_decay=1e-2\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def train(train_data, model, loss_fn, optimizer):\n",
    "    \n",
    "    rows, cols = train_data.nonzero()\n",
    "    p = np.random.permutation(len(rows))\n",
    "    rows, cols = rows[p], cols[p]\n",
    "\n",
    "    for row, col in zip(*(rows, cols)):\n",
    "\n",
    "        # Turn data into tensors\n",
    "        rating = torch.FloatTensor([train_data[row, col]]).squeeze()\n",
    "        row = torch.LongTensor([row])\n",
    "        cols = torch.LongTensor([col])\n",
    "        \n",
    "        # Compute prediction error\n",
    "        prediction = model(row, col)\n",
    "        loss = loss_fn(prediction, rating)\n",
    "\n",
    "        # Set gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(dataloader, model, loss_fn, optimizer):\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (rows, cols) in enumerate(dataloader):\n",
    "        rows_c, cols_c = rows.to(device), cols.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        rating = torch.tensor([dataloader.dataset.data[rows, cols]], device=device).squeeze()\n",
    "        prediction = model(rows_c, cols_c).to(torch.float64)\n",
    "        loss = loss_fn(prediction, rating)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 500 == 0:\n",
    "            loss, current = loss.item(), batch * len(rows)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 57.703419  [    0/99057]\n",
      "loss: 0.990580  [32000/99057]\n",
      "loss: 0.982432  [64000/99057]\n",
      "loss: 0.986696  [96000/99057]\n",
      "\n",
      "Metric: HR@10 = 0.1410;\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.985251  [    0/99057]\n",
      "loss: 0.985638  [32000/99057]\n",
      "loss: 0.983950  [64000/99057]\n",
      "loss: 0.985674  [96000/99057]\n",
      "\n",
      "Metric: HR@10 = 0.1400;\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.985696  [    0/99057]\n",
      "loss: 0.984553  [32000/99057]\n",
      "loss: 0.985555  [64000/99057]\n",
      "loss: 0.986022  [96000/99057]\n",
      "\n",
      "Metric: HR@10 = 0.1453;\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.985171  [    0/99057]\n",
      "loss: 0.986430  [32000/99057]\n",
      "loss: 0.986577  [64000/99057]\n",
      "loss: 0.985985  [96000/99057]\n",
      "\n",
      "Metric: HR@10 = 0.1485;\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.985141  [    0/99057]\n",
      "loss: 0.985428  [32000/99057]\n",
      "loss: 0.984548  [64000/99057]\n",
      "loss: 0.986467  [96000/99057]\n",
      "\n",
      "Metric: HR@10 = 0.1506;\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "    train_batch(train_dataloader, model, loss_fn, optimizer)\n",
    "    W = model.user_factors.mm(model.item_factors.T).cpu().detach().numpy()\n",
    "    ub = model.user_biases.cpu().detach().numpy()\n",
    "    ib = model.item_biases.cpu().detach().numpy()\n",
    "    w = W + ub + ib.T\n",
    "    print(f\"\\nMetric: HR@10 = {hr(test_data, test_dict, w, hm=10):.4f};\\n\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = model.user_factors.mm(model.item_factors.T).cpu().detach().numpy()\n",
    "ub = model.user_biases.detach().cpu().numpy()\n",
    "ib = model.item_biases.detach().cpu().numpy()\n",
    "w = W + ub + ib.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15058324496288442"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr(test_data, test_dict, w, hm=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WARP model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class MFWARP(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super(MFWARP, self).__init__()\n",
    "        \n",
    "        self.user_factors = Parameter(torch.randn(n_users, n_factors))\n",
    "        self.item_factors = Parameter(torch.randn(n_items, n_factors))\n",
    "        self.user_biases = Parameter(torch.randn(n_users, 1))\n",
    "        self.item_biases = Parameter(torch.randn(n_items, 1))\n",
    "        \n",
    "    def forward(self, users, items):\n",
    "        pred = (self.user_biases[users] + self.item_biases[items].T)\n",
    "        pred += (self.user_factors[users] @ self.item_factors[items].T)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFWARP()\n"
     ]
    }
   ],
   "source": [
    "n_factors = 50\n",
    "model = MFWARP(n_users, n_items, n_factors).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=5e-3, weight_decay=1e-2)\n",
    "loss_fn = WARPLoss(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch_warp(train_data, model, loss_fn, optimizer, bs=64, show=True):\n",
    "    user_idx = np.arange(train_data.shape[0])\n",
    "    np.random.shuffle(user_idx)\n",
    "    batches = np.array_split(user_idx, train_data.shape[0]//bs)\n",
    "    cols = torch.arange(train_data.shape[1])\n",
    "    cols_c = cols.to(device)\n",
    "    \n",
    "    for i, batch in enumerate(batches):\n",
    "        rows = torch.tensor(batch)\n",
    "        rows_c = rows.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        rating = torch.tensor([train_data[rows][:, cols]], device=device).squeeze()\n",
    "        prediction = model(rows_c, cols_c).to(torch.float64)\n",
    "        loss = loss_fn(prediction, rating)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if show and (i % 10 == 0):\n",
    "            loss, current = loss.item(), i * len(rows)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{train_data.shape[0]:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Metric: HR@10 = 0.0148;\n",
      "Epoch 21: Metric: HR@10 = 0.0212;\n",
      "Epoch 41: Metric: HR@10 = 0.0498;\n",
      "Epoch 61: Metric: HR@10 = 0.0742;\n",
      "Epoch 81: Metric: HR@10 = 0.0933;\n",
      "Epoch 101: Metric: HR@10 = 0.1124;\n",
      "Epoch 121: Metric: HR@10 = 0.1188;\n",
      "Epoch 141: Metric: HR@10 = 0.1251;\n",
      "Epoch 161: Metric: HR@10 = 0.1400;\n",
      "Epoch 181: Metric: HR@10 = 0.1453;\n",
      "Epoch 201: Metric: HR@10 = 0.1485;\n",
      "Epoch 221: Metric: HR@10 = 0.1485;\n",
      "Epoch 241: Metric: HR@10 = 0.1654;\n",
      "Epoch 261: Metric: HR@10 = 0.1697;\n",
      "Epoch 281: Metric: HR@10 = 0.1803;\n",
      "Epoch 301: Metric: HR@10 = 0.1919;\n",
      "Epoch 321: Metric: HR@10 = 0.1813;\n",
      "Epoch 341: Metric: HR@10 = 0.1792;\n",
      "Epoch 361: Metric: HR@10 = 0.2068;\n",
      "Epoch 381: Metric: HR@10 = 0.1962;\n",
      "Epoch 401: Metric: HR@10 = 0.2004;\n",
      "Epoch 421: Metric: HR@10 = 0.2015;\n",
      "Epoch 441: Metric: HR@10 = 0.1888;\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3130/501058362.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_batch_warp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_factors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_factors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_biases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3130/4251811306.py\u001b[0m in \u001b[0;36mtrain_batch_warp\u001b[0;34m(train_data, model, loss_fn, optimizer, bs, show)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mrating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.8.10/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3130/1108134999.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mWARP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_num_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_3130/1108134999.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input, target, max_num_trials)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mneg_labels_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_labels_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmsk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_score_margin\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_trials\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_num_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0;31m#randomly sample a negative label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "for epoch in range(epochs):\n",
    "    train_batch_warp(train_data, model, loss_fn, optimizer, 64, show=False)\n",
    "    W = model.user_factors.mm(model.item_factors.T).cpu().detach().numpy()\n",
    "    ub = model.user_biases.cpu().detach().numpy()\n",
    "    ib = model.item_biases.cpu().detach().numpy()\n",
    "    w = W + ub + ib.T\n",
    "    \n",
    "    if epoch % 20 == 0:   \n",
    "        print(f\"Epoch {epoch + 1}: Metric: HR@10 = {hr(test_data, test_dict, w, hm=10):.4f};\")\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
