{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from ipypb import track\n",
    "import argparse\n",
    "from torch.nn.init import xavier_normal_\n",
    "from torch import optim\n",
    "\n",
    "import torch\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from t_alg import mttcrp, mttcrp1, get_elem_deriv_tensor, factors_to_tensor, gcp_grad, multi_ind_to_indices, indices_to_multi_ind\n",
    "\n",
    "from samplings import give_ns, generate_data\n",
    "\n",
    "from elementwise_grads import bernoulli_logit_loss, bernoulli_logit_loss_grad, bernoulli_loss, bernoulli_loss_grad\n",
    "\n",
    "from general_functions1 import sqrt_err_relative, check_coo_tensor, gen_coo_tensor\n",
    "from general_functions1 import create_filter, hr\n",
    "\n",
    "from decimal import Decimal\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from experiments import data_storage, Trainer, run_epoch\n",
    "\n",
    "#import CP_ALS3.CP_ALS3 as cp\n",
    "\n",
    "#with open('test_filter.pkl', 'rb') as f:\n",
    "    #test_filter = pickle.load(f)\n",
    "    \n",
    "with open('/notebook/Relations_Learning/test_filter.pkl', 'rb') as f:\n",
    "    test_filter = pickle.load(f)\n",
    "    \n",
    "with open('/notebook/Relations_Learning/valid_filter.pkl', 'rb') as f:\n",
    "    valid_filter = pickle.load(f)\n",
    "    \n",
    "import numpy as np\n",
    "\n",
    "def static_vars(**kwargs):\n",
    "    def decorate(func):\n",
    "        for k in kwargs:\n",
    "            setattr(func, k, kwargs[k])\n",
    "        return func\n",
    "    return decorate\n",
    "\n",
    "\n",
    "@static_vars(fail_count=0)\n",
    "def check_early_stop(target_score, previous_best, margin=0, max_attempts=1000):\n",
    "    if (previous_best > target_score):\n",
    "        previous_best = target_score\n",
    "    if (margin >= 0) and (target_score > previous_best + margin):\n",
    "        check_early_stop.fail_count += 1\n",
    "    else:\n",
    "        check_early_stop.fail_count = 0\n",
    "    if check_early_stop.fail_count >= max_attempts:\n",
    "        print('Interrupted due to early stopping condition.', check_early_stop.fail_count, flush = True)\n",
    "        raise StopIteration\n",
    "\n",
    "@static_vars(fail_count_score=0)        \n",
    "def check_early_stop_score(target_score, previous_best, margin=0, max_attempts=3000):\n",
    "    if (previous_best > target_score):\n",
    "        previous_best = target_score\n",
    "    if (margin >= 0) and (target_score < previous_best + margin):\n",
    "        check_early_stop_score.fail_count_score += 1\n",
    "    else:\n",
    "        check_early_stop_score.fail_count_score = 0\n",
    "    if check_early_stop_score.fail_count_score >= max_attempts:\n",
    "        print('Interrupted due to early stopping scoring condition.', check_early_stop_score.fail_count_score, flush = True)\n",
    "        raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import FoxIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded1_\n",
      "(14541, 237, 14541)\n",
      "(14541, 237, 14541)\n"
     ]
    }
   ],
   "source": [
    "path_data = \"/notebook/Relations_Learning/Link_Prediction_Data/FB15K237/\"\n",
    "entity_list = pickle.load(open(path_data + 'entity_list', 'rb'))\n",
    "relation_list = pickle.load(open(path_data + 'relation_list', 'rb'))\n",
    "\n",
    "train_triples = pickle.load(open(path_data + 'train_triples', 'rb'))\n",
    "valid_triples = pickle.load(open(path_data + 'valid_triples', 'rb'))\n",
    "test_triples = pickle.load(open(path_data + 'test_triples', 'rb'))\n",
    "train_valid_triples = pickle.load(open(path_data + 'train_valid_triples', 'rb'))\n",
    "\n",
    "entity_map = pickle.load(open(path_data + 'entity_map', 'rb'))\n",
    "relation_map = pickle.load(open(path_data + 'relation_map', 'rb'))\n",
    "\n",
    "all_triples = train_valid_triples + test_triples\n",
    "\n",
    "print (\"loaded1_\", flush = True)\n",
    "num_epoch = 50\n",
    "rank = 200 \n",
    "lr = 1e-2\n",
    "seed = 13 \n",
    "hm = 1000\n",
    "how_many = 2\n",
    "l2 = 0\n",
    "    \n",
    "values = [1] * len(train_triples)\n",
    "values = np.array(values, dtype=np.int64)\n",
    "\n",
    "coords = np.array(train_triples, dtype=np.int64)\n",
    "nnz = len(train_triples)\n",
    "data_shape = (len(entity_list), len(relation_list), len(entity_list))\n",
    "    \n",
    "print (data_shape, flush = True)\n",
    "\n",
    "print (data_shape, flush = True)\n",
    "    \n",
    "coo_tensor = coords\n",
    "vals = values\n",
    "shape = data_shape\n",
    "\n",
    "device=torch.device(\"cuda:4\")\n",
    "\n",
    "num_epoch = 200\n",
    "\n",
    "random_state = np.random.seed(seed)\n",
    "\n",
    "    # specify property of data\n",
    "batch_size = 56\n",
    "init_mind_set = set(indices_to_multi_ind(coo_tensor, shape))\n",
    "coo_ns = np.empty((how_many * len(init_mind_set) + vals.size, 3), dtype=np.int64)\n",
    "vals_ns = np.empty((how_many * len(init_mind_set) + vals.size,), dtype=np.float64)\n",
    "    \n",
    "data_s = data_storage(sparse_coords = coords, sparse_vals =values, mind_set = init_mind_set, shape=data_shape, how_many=2, valid_filters = valid_filter, valid_triples = valid_triples)\n",
    "\n",
    "    # specify property of training\n",
    "err_arr = np.empty((num_epoch*vals_ns.shape[0]//batch_size + 1, ), dtype=np.float64)\n",
    "error = 0.0\n",
    "it = 0\n",
    "previous_best_loss = 100000.0\n",
    "best_hit_10 = 0.0\n",
    "# specify training class\n",
    "trainer = Trainer(best_hit_10, previous_best_loss, err_arr, it)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda:4\")\n",
    "model = FoxIE(rank=rank, shape=data_shape, given_loss=bernoulli_logit_loss, given_loss_grad=bernoulli_logit_loss_grad, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n"
     ]
    }
   ],
   "source": [
    "model.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_from_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False, device='cuda:4')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.b_torch.isnan().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam([model.a_torch, model.b_torch], lr=5e-4)\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "\n",
    "show_iter = True\n",
    "start = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816345 56 14577\n",
      "Iter:  0 ; Error:  1.1007932188562734e-05\n",
      "Iter:  500 ; Error:  0.0038273178574771273\n",
      "Iter:  1000 ; Error:  0.0026255469780785685\n",
      "Iter:  1500 ; Error:  0.0022281255138903717\n",
      "Iter:  2000 ; Error:  0.002318831283938394\n",
      "Iter:  2500 ; Error:  0.0025662577658137303\n",
      "Iter:  3000 ; Error:  0.002294940177683125\n",
      "Iter:  3500 ; Error:  0.002364985644292082\n",
      "Iter:  4000 ; Error:  0.0022372628618141104\n",
      "Iter:  4500 ; Error:  0.0024428811009452175\n",
      "Iter:  5000 ; Error:  0.0022826377044496706\n",
      "Iter:  5500 ; Error:  0.002246911448141118\n",
      "Iter:  6000 ; Error:  0.0023264866808626367\n",
      "Iter:  6500 ; Error:  0.00237607630526309\n",
      "Iter:  7000 ; Error:  0.0022832790085939064\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0920d11e30b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# early stopping condition met\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/Relations_Learning/gpu/experiments.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(datas, epoch, device, model, optimizer, sheduler, batch_size, trainer, show_iter)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mc_elems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoo_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoo_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_elems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_elems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_elems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/Relations_Learning/gpu/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, coo_ns, vals_ns, a_elems, b_elems, c_elems)\u001b[0m\n\u001b[1;32m     77\u001b[0m         loss, g_a, g_b, g_c = self.gcp_grad(\n\u001b[1;32m     78\u001b[0m             \u001b[0mcoo_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma_torch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_torch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         )\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/Relations_Learning/gpu/model.py\u001b[0m in \u001b[0;36mgcp_grad\u001b[0;34m(self, coo, val, shape, a, b, l2, loss_function, loss_function_grad, device)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Calculate gradients w.r.t. a, b, c factor matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mg_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmttcrp1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderiv_tensor_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mg_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmttcrp1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderiv_tensor_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mg_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmttcrp1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderiv_tensor_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/Relations_Learning/gpu/t_alg.py\u001b[0m in \u001b[0;36mmttcrp1\u001b[0;34m(coo, val, shape, mode, a, b, device)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# d = a[coo[i,mode_a], :] * b[coo[i,mode_b], :] * val[i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# print (\"d shape \", d.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcoo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode_a\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcoo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;31m# print (\"temp.shape\", temp.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    try:\n",
    "        run_epoch(data_s, epoch, device, model, optimizer, scheduler, batch_size, trainer, show_iter = True)\n",
    "    except StopIteration: # early stopping condition met\n",
    "        break\n",
    "        print (\"early_stoping loss\", flush = True)\n",
    "        raise StopIteration\n",
    "            \n",
    "\n",
    "    hit3, hit5, hit10, mrr = model.evaluate()\n",
    "    print (hit3, hit5, hit10, mrr, flush = True)\n",
    "        \n",
    "    # early stopping by hit@10\n",
    "    try:\n",
    "        check_early_stop_score(hit10, best_hit_10, margin=0.01, max_attempts=1000)\n",
    "    except StopIteration: # early stopping condition met\n",
    "            break\n",
    "            print (\"early_stoping score\", flush = True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
