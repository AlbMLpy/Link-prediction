{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from ipypb import track\n",
    "\n",
    "from general_functions1 import sqrt_err_relative, check_coo_tensor, gen_coo_tensor\n",
    "from general_functions1 import create_filter, hr\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/notebook/Relations_Learning/\") \n",
    "import CP_ALS3.CP_ALS3 as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebook/Relations_Learning/gpu\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/notebook/Relations_Learning/test_filter.pkl', 'rb') as f:\n",
    "    test_filter = pickle.load(f)\n",
    "    \n",
    "with open('/notebook/Relations_Learning/valid_filter.pkl', 'rb') as f:\n",
    "    valid_filter = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from t_alg import mttcrp, mttcrp1, get_elem_deriv_tensor, factors_to_tensor, gcp_grad, multi_ind_to_indices, indices_to_multi_ind\n",
    "\n",
    "from samplings import give_ns, generate_data\n",
    "\n",
    "from elementwise_grads import bernoulli_logit_loss, bernoulli_logit_loss_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17535"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "device=torch.device(\"cuda:4\")\n",
    "\n",
    "class GSP_SGD(torch.nn.Module):\n",
    "    def __init__(self, num_ent, num_rel, dim_emb, shape, loss_function, loss_function_grad):\n",
    "        super(GSP_SGD, self).__init__()\n",
    "                \n",
    "        self.ent = torch.empty((num_ent, dim_emb), device = device)\n",
    "        xavier_normal_(a_torch)\n",
    "        a_torch.requires_grad=True\n",
    "\n",
    "        self.rel = torch.empty((num_rel, dim_emb), device = device)\n",
    "        xavier_normal_(b_torch)\n",
    "        b_torch.requires_grad=True\n",
    "        \n",
    "        self.optimizer = optim.Adam([a_torch, b_torch, c_torch], lr=1e-3)\n",
    "        \n",
    "        self.coo = coo_tensor\n",
    "        self.vals = vals\n",
    "        self.shape = shape\n",
    "        self.elemwise_loss = loss_function\n",
    "        self.elemwise_grad = loss_function_grad\n",
    "\n",
    "        #c_torch = torch.empty((num_ent, dim_emb), device = device)\n",
    "        #xavier_normal_(c_torch)\n",
    "        #c_torch.requires_grad=True\n",
    "    \n",
    "    def forward(self, ent_idx, rel_idx):\n",
    "        pass\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gcp_grad(coo, val, shape, a, b, l2, loss_function, loss_function_grad, device):\n",
    "    \"\"\"\n",
    "        GCP loss function and gradient calculation.\n",
    "        All the tensors have the same coordinate set: coo_tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    # Construct sparse kruskal tensor\n",
    "    kruskal_val = torch.sum((a[coo[:,0], :] * b[coo[:,1], :] * a[coo[:,2], :]),1)\n",
    "    #factors_to_tensor(coo_tensor, vals, a, b, c)\n",
    "    \n",
    "    # Calculate mean loss on known entries\n",
    "    loss = loss_function(val, kruskal_val)\n",
    "    # Compute the elementwise derivative tensor\n",
    "    deriv_tensor_val = loss_function_grad(val, kruskal_val)\n",
    "    \n",
    "    #print (\"in qcp_grad in deriv_tensor_val \", deriv_tensor_val)\n",
    "    # Calculate gradients w.r.t. a, b, c factor matrices\n",
    "    g_a = mttcrp1(coo, deriv_tensor_val, shape, 0, b, a, device)\n",
    "    g_b = mttcrp1(coo, deriv_tensor_val, shape, 1, a, a, device)\n",
    "    g_c = mttcrp1(coo, deriv_tensor_val, shape, 2, a, b, device)\n",
    "    \n",
    "    #print (\"\\n\\n\")\n",
    "    \n",
    "    \n",
    "    # Add L2 regularization\n",
    "    if l2 != 0:\n",
    "        g_a += l2 * a[coo[0], :]\n",
    "        g_b += l2 * b[coo[1], :]\n",
    "        g_c += l2 * c[coo[2], :]\n",
    "    \n",
    "    return loss, g_a, g_b, g_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('/notebook/Relations_Learning/a200.npz', a)\n",
    "#np.save('/notebook/Relations_Learning/b200.npz', b)\n",
    "#np.save('/notebook/Relations_Learning/c200.npz', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d74f1bcdd37c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/notebook/Relations_Learning/results/gpu_a.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-4302d69244ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/notebook/Relations_Learning/results/gpu_a.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/notebook/Relations_Learning/results/gpu_b.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/notebook/Relations_Learning/results/gpu_c.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/notebook/Relations_Learning/results/gpu_a.npz'"
     ]
    }
   ],
   "source": [
    "a = np.load('/notebook/Relations_Learning/results/gpu_a.npz')\n",
    "b = np.load('/notebook/Relations_Learning/results/gpu_b.npz')\n",
    "c = np.load('/notebook/Relations_Learning/results/gpu_c.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"/notebook/Relations_Learning/Link_Prediction_Data/FB15K237/\"\n",
    "entity_list = pickle.load(open(path_data + 'entity_list', 'rb'))\n",
    "relation_list = pickle.load(open(path_data + 'relation_list', 'rb'))\n",
    "\n",
    "train_triples = pickle.load(open(path_data + 'train_triples', 'rb'))\n",
    "valid_triples = pickle.load(open(path_data + 'valid_triples', 'rb'))\n",
    "test_triples = pickle.load(open(path_data + 'test_triples', 'rb'))\n",
    "train_valid_triples = pickle.load(open(path_data + 'train_valid_triples', 'rb'))\n",
    "\n",
    "entity_map = pickle.load(open(path_data + 'entity_map', 'rb'))\n",
    "relation_map = pickle.load(open(path_data + 'relation_map', 'rb'))\n",
    "\n",
    "all_triples = train_valid_triples + test_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272115"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_filter = create_filter(test_triples, all_triples)\n",
    "#train_filter = create_filter(train_triples, all_triples)  \n",
    "#valid_filter = create_filter(valid_triples, all_triples)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('train_filter.pkl', 'wb') as handle:\n",
    "    #pickle.dump(train_filter, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/notebook/Relations_Learning/test_filter.pkl', 'rb') as f:\n",
    "    test_filter = pickle.load(f)\n",
    "    \n",
    "with open('/notebook/Relations_Learning/valid_filter.pkl', 'rb') as f:\n",
    "    valid_filter = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14541, 237, 14541)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = [1] * len(train_triples)\n",
    "values = np.array(values, dtype=np.int64)\n",
    "\n",
    "coords = np.array(train_triples, dtype=np.int64)\n",
    "nnz = len(train_triples)\n",
    "data_shape = (len(entity_list), len(relation_list), len(entity_list))\n",
    "data_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 1000 \n",
    "rank = 100 \n",
    "l2 =  0\n",
    "lr = 1e-2 \n",
    "seed = 13 \n",
    "hm = 1000\n",
    "how_many = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 17 12:03:40 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.03   Driver Version: 450.119.03   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 27%   30C    P8    13W / 260W |   1968MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 27%   28C    P8     9W / 260W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:1C:00.0 Off |                  N/A |\n",
      "| 27%   31C    P8     5W / 260W |   1678MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   32C    P8    11W / 260W |   1366MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  Off  | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 29%   43C    P2    51W / 260W |   2517MiB / 11019MiB |     11%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  Off  | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 90%   81C    P2   258W / 260W |   9780MiB / 11019MiB |     98%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  Off  | 00000000:40:00.0 Off |                  N/A |\n",
      "| 83%   75C    P2   257W / 260W |   9780MiB / 11019MiB |     97%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  Off  | 00000000:41:00.0 Off |                  N/A |\n",
      "| 71%   68C    P2   258W / 260W |   9780MiB / 11019MiB |     97%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'err_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2445ec064380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0merr_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'err_list' is not defined"
     ]
    }
   ],
   "source": [
    "err_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816345 56 14577\n",
      "Iter:  0 ; Error:  0.6931426404652744\n",
      "Iter:  500 ; Error:  0.6931448181376691\n",
      "Iter:  1000 ; Error:  0.6931259831014395\n",
      "Iter:  1500 ; Error:  0.6930076131455367\n",
      "Iter:  2000 ; Error:  0.6924960714221322\n",
      "Iter:  2500 ; Error:  0.6911811214942308\n",
      "Iter:  3000 ; Error:  0.6886549989208472\n",
      "Iter:  3500 ; Error:  0.6851194491714021\n",
      "Iter:  4000 ; Error:  0.6804785100865407\n",
      "Iter:  4500 ; Error:  0.6751001314411018\n",
      "Iter:  5000 ; Error:  0.6688967129989343\n",
      "Iter:  5500 ; Error:  0.6623912733726212\n",
      "Iter:  6000 ; Error:  0.6557488714034669\n",
      "Iter:  6500 ; Error:  0.6489698550831051\n",
      "Iter:  7000 ; Error:  0.6422769228120526\n",
      "Iter:  7500 ; Error:  0.6357087923589181\n",
      "Iter:  8000 ; Error:  0.6290571567597771\n",
      "Iter:  8500 ; Error:  0.6224255486734745\n",
      "Iter:  9000 ; Error:  0.6156572949817392\n",
      "Iter:  9500 ; Error:  0.6086810934407346\n",
      "Iter:  10000 ; Error:  0.6012435596833925\n",
      "Iter:  10500 ; Error:  0.5932137194358816\n",
      "Iter:  11000 ; Error:  0.5841045068556182\n",
      "Iter:  11500 ; Error:  0.5741783603679865\n",
      "Iter:  12000 ; Error:  0.5632242128687016\n",
      "Iter:  12500 ; Error:  0.5516062605827894\n",
      "Iter:  13000 ; Error:  0.5393572464223364\n",
      "Iter:  13500 ; Error:  0.5269997286620607\n",
      "Iter:  14000 ; Error:  0.5146426666455326\n",
      "Iter:  14500 ; Error:  0.5025251275865372\n",
      "count hr\n",
      "(0.202, 0.296, 0.415, 0.2750176106490988)\n",
      "424.17032891500276\n",
      "816345 56 14577\n",
      "Iter:  14577 ; Error:  0.15133320506928222\n",
      "Iter:  15077 ; Error:  0.13767601897193557\n",
      "Iter:  15577 ; Error:  0.13278511996042278\n",
      "Iter:  16077 ; Error:  0.12686628606844316\n",
      "Iter:  16577 ; Error:  0.1211330302848775\n",
      "Iter:  17077 ; Error:  0.11682996925225828\n",
      "Iter:  17577 ; Error:  0.11303892878102562\n",
      "Iter:  18077 ; Error:  0.11001050258707798\n",
      "Iter:  18577 ; Error:  0.10696795061691364\n",
      "Iter:  19077 ; Error:  0.10392744520105025\n",
      "Iter:  19577 ; Error:  0.1013368077664805\n",
      "Iter:  20077 ; Error:  0.09892354418585758\n",
      "Iter:  20577 ; Error:  0.09669677186887003\n",
      "Iter:  21077 ; Error:  0.09446037122629095\n",
      "Iter:  21577 ; Error:  0.09245630939505821\n",
      "Iter:  22077 ; Error:  0.0903769625070346\n",
      "Iter:  22577 ; Error:  0.0883866480262265\n",
      "Iter:  23077 ; Error:  0.08660258125032932\n",
      "Iter:  23577 ; Error:  0.08496194015563396\n",
      "Iter:  24077 ; Error:  0.08338006285399112\n",
      "Iter:  24577 ; Error:  0.08181613722900587\n",
      "Iter:  25077 ; Error:  0.0802985198716152\n",
      "Iter:  25577 ; Error:  0.07900202174811459\n",
      "Iter:  26077 ; Error:  0.0777523451475158\n",
      "Iter:  26577 ; Error:  0.07654408336335061\n",
      "Iter:  27077 ; Error:  0.07545170103046761\n",
      "Iter:  27577 ; Error:  0.07433290076282208\n",
      "Iter:  28077 ; Error:  0.07327231626143679\n",
      "Iter:  28577 ; Error:  0.07211815729615124\n",
      "Iter:  29077 ; Error:  0.07096670270186893\n",
      "count hr\n",
      "(0.22, 0.329, 0.472, 0.30327421678411054)\n",
      "846.69170028402\n",
      "816345 56 14577\n",
      "Iter:  29154 ; Error:  0.008432818301440952\n",
      "Iter:  29654 ; Error:  0.02929415835884317\n",
      "Iter:  30154 ; Error:  0.029523035408983274\n",
      "Iter:  30654 ; Error:  0.028852961263023835\n",
      "Iter:  31154 ; Error:  0.028539476421718602\n",
      "Iter:  31654 ; Error:  0.02835833409277478\n",
      "Iter:  32154 ; Error:  0.02821940534284521\n",
      "Iter:  32654 ; Error:  0.02823440797798216\n",
      "Iter:  33154 ; Error:  0.027854052233433308\n",
      "Iter:  33654 ; Error:  0.028003689678280087\n",
      "Iter:  34154 ; Error:  0.02809044068390539\n",
      "Iter:  34654 ; Error:  0.027801939881904863\n",
      "Iter:  35154 ; Error:  0.027675385988571114\n",
      "Iter:  35654 ; Error:  0.02734537351734105\n",
      "Iter:  36154 ; Error:  0.027106653488359795\n",
      "Iter:  36654 ; Error:  0.0270720262165296\n",
      "Iter:  37154 ; Error:  0.026963976471046213\n",
      "Iter:  37654 ; Error:  0.02676046463905247\n",
      "Iter:  38154 ; Error:  0.026574773678314196\n",
      "Iter:  38654 ; Error:  0.026403434192817286\n",
      "Iter:  39154 ; Error:  0.026216466242241183\n",
      "Iter:  39654 ; Error:  0.025999296420358222\n",
      "Iter:  40154 ; Error:  0.025900684056341338\n",
      "Iter:  40654 ; Error:  0.025846416339766327\n",
      "Iter:  41154 ; Error:  0.025686877304487165\n",
      "Iter:  41654 ; Error:  0.025414203337907833\n",
      "Iter:  42154 ; Error:  0.02531520088851233\n",
      "Iter:  42654 ; Error:  0.025227696973216\n",
      "Iter:  43154 ; Error:  0.025138827735170306\n",
      "Iter:  43654 ; Error:  0.024964868839571747\n",
      "count hr\n",
      "(0.231, 0.34, 0.475, 0.31315367877041383)\n",
      "1268.7596367050137\n",
      "816345 56 14577\n",
      "Iter:  43731 ; Error:  0.0073618234040013775\n",
      "Iter:  44231 ; Error:  0.020028265817329794\n",
      "Iter:  44731 ; Error:  0.018471629646689053\n",
      "Iter:  45231 ; Error:  0.018936030028139383\n",
      "Iter:  45731 ; Error:  0.01906430374412212\n",
      "Iter:  46231 ; Error:  0.018494228372136465\n",
      "Iter:  46731 ; Error:  0.018291647126427654\n",
      "Iter:  47231 ; Error:  0.01818200519382951\n",
      "Iter:  47731 ; Error:  0.01789302153242315\n",
      "Iter:  48231 ; Error:  0.01779169656709319\n",
      "Iter:  48731 ; Error:  0.017732654057597427\n",
      "Iter:  49231 ; Error:  0.01760026742002562\n",
      "Iter:  49731 ; Error:  0.01752713364385705\n",
      "Iter:  50231 ; Error:  0.01748571346410073\n",
      "Iter:  50731 ; Error:  0.017592398172944154\n",
      "Iter:  51231 ; Error:  0.017558410590377167\n",
      "Iter:  51731 ; Error:  0.017426193741633848\n",
      "Iter:  52231 ; Error:  0.017524344679238336\n",
      "Iter:  52731 ; Error:  0.017460499138232128\n",
      "Iter:  53231 ; Error:  0.01741687610196374\n",
      "Iter:  53731 ; Error:  0.017403523116995966\n",
      "Iter:  54231 ; Error:  0.01730422822749852\n",
      "Iter:  54731 ; Error:  0.017340223462808262\n",
      "Iter:  55231 ; Error:  0.017392116366161347\n",
      "Iter:  55731 ; Error:  0.017301306444809785\n",
      "Iter:  56231 ; Error:  0.01719198771009541\n",
      "Iter:  56731 ; Error:  0.01711378303970564\n",
      "Iter:  57231 ; Error:  0.01702702695972533\n",
      "Iter:  57731 ; Error:  0.017038610555194917\n",
      "Iter:  58231 ; Error:  0.017056847108401687\n",
      "count hr\n",
      "(0.213, 0.316, 0.474, 0.2947913599211661)\n",
      "1672.9222109680122\n",
      "816345 56 14577\n",
      "Iter:  58308 ; Error:  0.09953890496033908\n",
      "Iter:  58808 ; Error:  0.012287785278844108\n",
      "Iter:  59308 ; Error:  0.012399488654555223\n",
      "Iter:  59808 ; Error:  0.012029793611071976\n",
      "Iter:  60308 ; Error:  0.011873665269615858\n",
      "Iter:  60808 ; Error:  0.012121027993542506\n",
      "Iter:  61308 ; Error:  0.012210502277166808\n",
      "Iter:  61808 ; Error:  0.012494018407082199\n",
      "Iter:  62308 ; Error:  0.012520929004673024\n",
      "Iter:  62808 ; Error:  0.012334258711851185\n",
      "Iter:  63308 ; Error:  0.012585974090426458\n",
      "Iter:  63808 ; Error:  0.012653212984689239\n",
      "Iter:  64308 ; Error:  0.012554886761557821\n",
      "Iter:  64808 ; Error:  0.012506851133548085\n",
      "Iter:  65308 ; Error:  0.012542682187214877\n",
      "Iter:  65808 ; Error:  0.012531589697828062\n",
      "Iter:  66308 ; Error:  0.01251058256844764\n",
      "Iter:  66808 ; Error:  0.01262942218857424\n",
      "Iter:  67308 ; Error:  0.01268242165370932\n",
      "Iter:  67808 ; Error:  0.012645362463602036\n",
      "Iter:  68308 ; Error:  0.012622742646841168\n",
      "Iter:  68808 ; Error:  0.012621096509172003\n",
      "Iter:  69308 ; Error:  0.012576269599023488\n",
      "Iter:  69808 ; Error:  0.012554299101742834\n",
      "Iter:  70308 ; Error:  0.012469998696657042\n",
      "Iter:  70808 ; Error:  0.012515954747785338\n",
      "Iter:  71308 ; Error:  0.012477194424138017\n",
      "Iter:  71808 ; Error:  0.01246861582717346\n",
      "Iter:  72308 ; Error:  0.012506558941893274\n",
      "Iter:  72808 ; Error:  0.012519616756155724\n",
      "count hr\n",
      "(0.22, 0.325, 0.473, 0.30214589792130686)\n",
      "2079.84828999202\n",
      "816345 56 14577\n",
      "Iter:  72885 ; Error:  0.014909383522820516\n",
      "Iter:  73385 ; Error:  0.009590954479256297\n",
      "Iter:  73885 ; Error:  0.010556924236543506\n",
      "Iter:  74385 ; Error:  0.011041044708045586\n",
      "Iter:  74885 ; Error:  0.011126355291673173\n",
      "Iter:  75385 ; Error:  0.010646498132217727\n",
      "Iter:  75885 ; Error:  0.010712093493473374\n",
      "Iter:  76385 ; Error:  0.010689038908058161\n",
      "Iter:  76885 ; Error:  0.010729113819291392\n",
      "Iter:  77385 ; Error:  0.010993880129738726\n",
      "Iter:  77885 ; Error:  0.010789429771100624\n",
      "Iter:  78385 ; Error:  0.01093511104220276\n",
      "Iter:  78885 ; Error:  0.010935388398435173\n",
      "Iter:  79385 ; Error:  0.01078308153182014\n",
      "Iter:  79885 ; Error:  0.010724178029903098\n",
      "Iter:  80385 ; Error:  0.010668757080095539\n",
      "Iter:  80885 ; Error:  0.010641818587340542\n",
      "Iter:  81385 ; Error:  0.010765266883903531\n",
      "Iter:  81885 ; Error:  0.010801869322545978\n",
      "Iter:  82385 ; Error:  0.010751884371162885\n",
      "Iter:  82885 ; Error:  0.010744424393762858\n",
      "Iter:  83385 ; Error:  0.010669691637451056\n",
      "Iter:  83885 ; Error:  0.01069313975253752\n",
      "Iter:  84385 ; Error:  0.010588101431040668\n",
      "Iter:  84885 ; Error:  0.010653628331430413\n",
      "Iter:  85385 ; Error:  0.010624350688784711\n",
      "Iter:  85885 ; Error:  0.010630744179961476\n",
      "Iter:  86385 ; Error:  0.010675301629821504\n",
      "Iter:  86885 ; Error:  0.010652758961568138\n",
      "Iter:  87385 ; Error:  0.010670661287571938\n",
      "count hr\n",
      "(0.219, 0.319, 0.475, 0.2996215787273112)\n",
      "2504.2537161780056\n",
      "816345 56 14577\n",
      "Iter:  87462 ; Error:  0.00024327334946911655\n",
      "Iter:  87962 ; Error:  0.01045301405767288\n",
      "Iter:  88462 ; Error:  0.010221107724767642\n",
      "Iter:  88962 ; Error:  0.010370122164666396\n",
      "Iter:  89462 ; Error:  0.009772102246901535\n",
      "Iter:  89962 ; Error:  0.009558161117414844\n",
      "Iter:  90462 ; Error:  0.009332615664024494\n",
      "Iter:  90962 ; Error:  0.00930174811913658\n",
      "Iter:  91462 ; Error:  0.00947089113551343\n",
      "Iter:  91962 ; Error:  0.009500711498733666\n",
      "Iter:  92462 ; Error:  0.009429240336491437\n",
      "Iter:  92962 ; Error:  0.009350885292352486\n",
      "Iter:  93462 ; Error:  0.009455299692617172\n",
      "Iter:  93962 ; Error:  0.00939583683212648\n",
      "Iter:  94462 ; Error:  0.009452200117727187\n",
      "Iter:  94962 ; Error:  0.009544594505258288\n",
      "Iter:  95462 ; Error:  0.009596280321009973\n",
      "Iter:  95962 ; Error:  0.009590843568635292\n",
      "Iter:  96462 ; Error:  0.009585526775666394\n",
      "Iter:  96962 ; Error:  0.009685273759099357\n",
      "Iter:  97462 ; Error:  0.009683638477749447\n",
      "Iter:  97962 ; Error:  0.00971415322636343\n",
      "Iter:  98462 ; Error:  0.009645522398415369\n",
      "Iter:  98962 ; Error:  0.009594780735760443\n",
      "Iter:  99462 ; Error:  0.009640561542124847\n",
      "Iter:  99962 ; Error:  0.009665487441850187\n",
      "Iter:  100462 ; Error:  0.009728754806412668\n",
      "Iter:  100962 ; Error:  0.009724267758987645\n",
      "Iter:  101462 ; Error:  0.009725502438017663\n",
      "Iter:  101962 ; Error:  0.009753817381775035\n",
      "count hr\n",
      "(0.217, 0.329, 0.471, 0.30026361884994024)\n",
      "2975.1676223970135\n",
      "816345 56 14577\n",
      "Iter:  102039 ; Error:  0.001298810352439236\n",
      "Iter:  102539 ; Error:  0.00982881588128607\n",
      "Iter:  103039 ; Error:  0.009321851539881644\n",
      "Iter:  103539 ; Error:  0.008932104355797957\n",
      "Iter:  104039 ; Error:  0.009049766307634653\n",
      "Iter:  104539 ; Error:  0.008519538256291268\n",
      "Iter:  105039 ; Error:  0.008458919386126655\n",
      "Iter:  105539 ; Error:  0.008459119808399048\n",
      "Iter:  106039 ; Error:  0.008756689785964587\n",
      "Iter:  106539 ; Error:  0.008638320190699655\n",
      "Iter:  107039 ; Error:  0.008737087793187971\n",
      "Iter:  107539 ; Error:  0.008765835060475777\n",
      "Iter:  108039 ; Error:  0.008766493068605392\n",
      "Iter:  108539 ; Error:  0.008778266255767183\n",
      "Iter:  109039 ; Error:  0.008750262319899383\n",
      "Iter:  109539 ; Error:  0.008817311529425912\n",
      "Iter:  110039 ; Error:  0.008730994492052653\n",
      "Iter:  110539 ; Error:  0.008737884655252088\n",
      "Iter:  111039 ; Error:  0.0087926489483458\n",
      "Iter:  111539 ; Error:  0.008780491809082898\n",
      "Iter:  112039 ; Error:  0.008838519896964953\n",
      "Iter:  112539 ; Error:  0.008875252585082335\n",
      "Iter:  113039 ; Error:  0.008922801155574117\n",
      "Iter:  113539 ; Error:  0.008922008228299994\n",
      "Iter:  114039 ; Error:  0.008869603920581452\n",
      "Iter:  114539 ; Error:  0.008817504352644117\n",
      "Iter:  115039 ; Error:  0.008844287419977682\n",
      "Iter:  115539 ; Error:  0.008853944820434105\n",
      "Iter:  116039 ; Error:  0.008878543942374055\n",
      "Iter:  116539 ; Error:  0.008865321750907752\n",
      "count hr\n",
      "(0.21, 0.316, 0.47, 0.2932382942815133)\n",
      "3413.304985054012\n",
      "816345 56 14577\n",
      "Iter:  116616 ; Error:  0.0004580162601746096\n",
      "Iter:  117116 ; Error:  0.00945104030990205\n",
      "Iter:  117616 ; Error:  0.008519390931109254\n",
      "Iter:  118116 ; Error:  0.008451219010833228\n",
      "Iter:  118616 ; Error:  0.008394148295201504\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-59a78df1a171>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m         loss, g_a, g_b, g_c = gcp_grad(\n\u001b[1;32m     61\u001b[0m             \u001b[0mcoo_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_torch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_torch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         )\n\u001b[1;32m     64\u001b[0m         \u001b[0merr_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f297fb083821>\u001b[0m in \u001b[0;36mgcp_grad\u001b[0;34m(coo, val, shape, a, b, l2, loss_function, loss_function_grad, device)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Calculate gradients w.r.t. a, b, c factor matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mg_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmttcrp1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderiv_tensor_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mg_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmttcrp1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderiv_tensor_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mg_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmttcrp1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderiv_tensor_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/Relations_Learning/gpu/t_alg.py\u001b[0m in \u001b[0;36mmttcrp1\u001b[0;34m(coo, val, shape, mode, a, b, device)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# d = a[coo[i,mode_a], :] * b[coo[i,mode_b], :] * val[i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# print (\"d shape \", d.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcoo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode_a\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcoo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;31m# print (\"temp.shape\", temp.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "coo_tensor = coords\n",
    "vals = values\n",
    "shape = data_shape\n",
    "loss_function = bernoulli_logit_loss\n",
    "loss_function_grad = bernoulli_logit_loss_grad\n",
    "\n",
    "from torch.nn.init import xavier_normal_\n",
    "from torch import optim\n",
    "\n",
    "device=torch.device(\"cuda:1\")\n",
    "\n",
    "num_epoch = 12\n",
    "\n",
    "random_state = np.random.seed(seed)\n",
    "\n",
    "batch_size = 56\n",
    "init_mind_set = set(indices_to_multi_ind(coo_tensor, shape))\n",
    "coo_ns = np.empty((how_many * len(init_mind_set) + vals.size, 3), dtype=np.int64)\n",
    "vals_ns = np.empty((how_many * len(init_mind_set) + vals.size,), dtype=np.float64)\n",
    "\n",
    "err_arr = np.empty((num_epoch*vals_ns.shape[0]//batch_size + 1, ), dtype=np.float64)\n",
    "error = 0.0\n",
    "it = 0\n",
    "\n",
    "num_ent = 14541\n",
    "dim_emb = 200\n",
    "num_rel = 237\n",
    "\n",
    "a_torch = torch.empty((num_ent, dim_emb), requires_grad = True, device = device)\n",
    "xavier_normal_(a_torch)\n",
    "a_torch.grad = torch.zeros(a_torch.shape, device = device)\n",
    "\n",
    "b_torch = torch.empty((num_rel, dim_emb), requires_grad = True, device = device)\n",
    "xavier_normal_(b_torch)\n",
    "b_torch.grad = torch.zeros(b_torch.shape, device = device)\n",
    "\n",
    "optimizer = optim.Adam([a_torch, b_torch], lr=1e-3)\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "\n",
    "show_iter = True\n",
    "\n",
    "start = timer()\n",
    "for epoch in range(num_epoch):\n",
    "    coo_ns, vals_ns = generate_data(coo_tensor, vals, init_mind_set, shape, how_many, epoch)\n",
    "    coo_ns = torch.tensor(coo_ns, device = device)\n",
    "    vals_ns = torch.tensor(vals_ns, device = device)\n",
    "    shuffler = np.random.permutation(vals_ns.shape[0])\n",
    "    coo_ns = coo_ns[shuffler]\n",
    "    vals_ns = vals_ns[shuffler]\n",
    "    #idxs = np.random.permutation(vals_ns.shape[0])\n",
    "    print (vals_ns.shape[0], batch_size, vals_ns.shape[0]//batch_size)\n",
    "    err_list = []\n",
    "    for i in range(vals_ns.shape[0]//batch_size):\n",
    "        # Get loss and gradients per sample\n",
    "        # print (\"coo_ns[i], vals_ns[i]\", coo_ns[i], vals_ns[i])\n",
    "        end = min(vals_ns.shape[0] - 1, (i+1)*batch_size)\n",
    "        loss, g_a, g_b, g_c = gcp_grad(\n",
    "            coo_ns[i*batch_size : end], vals_ns[i*batch_size : end], shape, a_torch, b_torch,\n",
    "            l2, loss_function, loss_function_grad, device\n",
    "        )\n",
    "        err_list.append(loss.cpu().detach().numpy().mean())\n",
    "\n",
    "        a_elems = coo_ns[i*batch_size : end, 0]\n",
    "        b_elems = coo_ns[i*batch_size : end, 1]\n",
    "        c_elems = coo_ns[i*batch_size : end, 2]\n",
    "        \n",
    "        a_torch.grad[a_elems, :] = g_a\n",
    "        b_torch.grad[b_elems, :] = g_b\n",
    "        a_torch.grad[c_elems, :] = g_c\n",
    "        optimizer.step()\n",
    "        a_torch.grad = torch.zeros(a_torch.shape, device = device)\n",
    "        b_torch.grad = torch.zeros(b_torch.shape, device = device)\n",
    "        \n",
    "        err_arr[it] = np.mean(err_list)\n",
    "        if show_iter and i%500 == 0:\n",
    "            print(\"Iter: \", it, \"; Error: \", np.mean(np.array(err_list)))\n",
    "        it += 1   \n",
    "    scheduler.step()\n",
    "    a = a_torch.cpu().data.numpy()\n",
    "    b = b_torch.cpu().data.numpy()\n",
    "    c = a_torch.cpu().data.numpy()\n",
    "    print (\"count hr\")\n",
    "    print (hr(valid_filter[:1000], valid_triples[:1000], a, b, c, [1, 3, 10]) )\n",
    "    end = timer()\n",
    "    print (end - start)\n",
    "    np.save('/notebook/Relations_Learning/results/gpu_a.npz', a_torch.cpu().data.numpy())\n",
    "    np.save('/notebook/Relations_Learning/results/gpu_b.npz', b_torch.cpu().data.numpy())\n",
    "    np.save('/notebook/Relations_Learning/results/gpu_c.npz', a_torch.cpu().data.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.1 s, sys: 160 ms, total: 7.26 s\n",
      "Wall time: 7.57 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.21, 0.316, 0.47, 0.2932382942815133)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "hr(valid_filter[:1000], valid_triples[:1000], a, b, c, [1, 3, 10])  #[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hr(valid_filter, valid_triples, a, b, c, [1, 3, 10])  #[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hr(test_filter, test_triples, a, b, c, [1, 3, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable, Function\n",
    "import random\n",
    "\n",
    "import math\n",
    "\n",
    "class WARP(Function): \n",
    "    '''\n",
    "    autograd function of WARP loss\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def forward(input, target, max_num_trials = None):\n",
    "        \n",
    "        batch_size = target.size()[0]\n",
    "        \n",
    "        if max_num_trials is None: \n",
    "            max_num_trials = target.size()[1] - 1\n",
    "        \n",
    "        positive_indices = torch.zeros(input.size())\n",
    "        negative_indices = torch.zeros(input.size())\n",
    "        L = torch.zeros(input.size()[0])\n",
    "        \n",
    "        all_labels_idx = np.arange(target.size()[1])\n",
    "        \n",
    "        Y = float(target.size()[1])\n",
    "        J = torch.nonzero(target)\n",
    "\n",
    "        for i in range(batch_size): \n",
    "            \n",
    "            msk = np.ones(target.size()[1], dtype = bool)\n",
    "            \n",
    "            # Find the positive label for this example\n",
    "            j = J[i, 1]\n",
    "            positive_indices[i, j] = 1\n",
    "            msk[j] = False\n",
    "            \n",
    "            # initialize the sample_score_margin\n",
    "            sample_score_margin = -1\n",
    "            num_trials = 0\n",
    "            \n",
    "            neg_labels_idx = all_labels_idx[msk]\n",
    "\n",
    "            while ((sample_score_margin < 0) and (num_trials < max_num_trials)):\n",
    "                 \n",
    "                #randomly sample a negative label\n",
    "                neg_idx = random.sample(list(neg_labels_idx), 1)[0]\n",
    "                msk[neg_idx] = False\n",
    "                neg_labels_idx = all_labels_idx[msk]\n",
    "                \n",
    "                num_trials += 1\n",
    "                # calculate the score margin \n",
    "                sample_score_margin = 1 + input[i, neg_idx] - input[i, j] \n",
    "            \n",
    "            if sample_score_margin < 0:\n",
    "                # checks if no violating examples have been found \n",
    "                continue\n",
    "            else: \n",
    "                loss_weight = np.log(math.floor((Y-1)/(num_trials)))\n",
    "                L[i] = loss_weight\n",
    "                negative_indices[i, neg_idx] = 1\n",
    "                \n",
    "        loss = L * (1-torch.sum(positive_indices*input, dim = 1) + torch.sum(negative_indices*input, dim = 1))\n",
    "        \n",
    "        # ctx.save_for_backward(input, target)\n",
    "        # ctx.L = L\n",
    "        # ctx.positive_indices = positive_indices\n",
    "        # ctx.negative_indices = negative_indices\n",
    "        \n",
    "        return torch.sum(loss , dim = 0, keepdim = True)\n",
    "\n",
    "    # This function has only a single output, so it gets only one gradient \n",
    "    @staticmethod\n",
    "    def backward(input, target, grad_output):\n",
    "        #input, target = ctx.saved_variables\n",
    "        L = Variable(torch.unsqueeze(ctx.L, 1), requires_grad = False)\n",
    "\n",
    "        positive_indices = Variable(ctx.positive_indices, requires_grad = False) \n",
    "        negative_indices = Variable(ctx.negative_indices, requires_grad = False)\n",
    "        grad_input = grad_output*L*(negative_indices - positive_indices)\n",
    "\n",
    "        return grad_input, None, None    \n",
    "\n",
    "      \n",
    "class WARPLoss(nn.Module): \n",
    "    def __init__(self, max_num_trials = None): \n",
    "        super(WARPLoss, self).__init__()\n",
    "        self.max_num_trials = max_num_trials\n",
    "        \n",
    "    def forward(self, input, target): \n",
    "        return WARP.apply(input, target, self.max_num_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('/notebook/Relations_Learning/a200.npz.npy')\n",
    "b = np.load('/notebook/Relations_Learning/b200.npz.npy')\n",
    "c = np.load('/notebook/Relations_Learning/c200.npz.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_warp = 0.001\n",
    "epoch =0\n",
    "\n",
    "wp = WARP()\n",
    "while (epoch < 1):\n",
    "    print (\"warp loss!\")\n",
    "    a_torch = torch.tensor(a, requires_grad=True)\n",
    "    b_torch = torch.tensor(b, requires_grad=True)\n",
    "    c_torch = torch.tensor(c, requires_grad=True)\n",
    "    list_of_inputs = []\n",
    "    list_of_targets = []\n",
    "    for entity, filt in zip(test_triples, test_filter):\n",
    "        p = entity[0]\n",
    "        q = entity[1]\n",
    "        r = entity[2]\n",
    "\n",
    "        candidate_values = torch.sum(a_torch[p, :] * b_torch[q, :] * c_torch, axis=1)\n",
    "\n",
    "        for obj in filt:\n",
    "            idxs = (candidate_values == obj).nonzero(as_tuple=False)\n",
    "            candidate_values[idxs] = 0.0\n",
    "            \n",
    "        candidate_values = torch.sigmoid(candidate_values)\n",
    "\n",
    "        target = torch.zeros(len(candidate_values))\n",
    "        target[r] = 1.0\n",
    "        list_of_inputs.append(candidate_values)\n",
    "        list_of_targets.append(target)\n",
    "\n",
    "    inputs = torch.stack(list_of_inputs)\n",
    "    print (list_of_inputs[0].shape, inputs.shape) #should be batch_size*\n",
    "    targets = torch.stack(list_of_targets)\n",
    "    print (list_of_targets[0].shape, targets.shape) #should be batch_size*\n",
    "    \n",
    "    #batch_size = 16\n",
    "    #for i in range(inputs.shape[0]//batch_size):\n",
    "        #print (i)\n",
    "        #end = min(inputs.shape[0] - 1, (i+1)*batch_size)\n",
    "    loss = wp.forward(inputs, targets) \n",
    "    print (\"warp loss is counted\", loss)\n",
    "\n",
    "        #if (i ==0):\n",
    "    loss.backward()\n",
    "    \n",
    "\n",
    "    a = a - lr_warp*a_torch.grad.data.numpy()\n",
    "    b = b - lr_warp*b_torch.grad.data.numpy()\n",
    "    c = c - lr_warp*c_torch.grad.data.numpy()\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"HR@10\")\n",
    "plt.title(f\"FB15k-237 / GCP-GD3(R={rank}) G\")\n",
    "plt.plot(np.arange(1, it+1), hr_arr[:it, 2], '-*', c=\"#8b0a50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@jit(nopython=True)\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "#@jit(nopython=True)\n",
    "def hr(test_filter, test_triples, a, b, c,\n",
    "       how_many=[1, 3, 10], iter_show=False, freq=3000):\n",
    "    \"\"\" Calculate HR@[how_many] and MRR using filter \"\"\"\n",
    "    \n",
    "    total = len(test_triples)\n",
    "    hit = [0, 0, 0, 0]\n",
    "    iteration = 0\n",
    "    for entity, filt in zip(test_triples, test_filter):\n",
    "        p = entity[0]\n",
    "        q = entity[1]\n",
    "        r = entity[2]\n",
    "\n",
    "        candidate_values = np.sum(a[p, :] * b[q, :] * c, axis=1)\n",
    "        candidate_values = sigmoid(candidate_values)\n",
    "        \n",
    "        top = np.argsort(candidate_values)[::-1]\n",
    "        top = list(top)\n",
    "        \n",
    "        for obj in filt:\n",
    "            top.remove(obj)\n",
    "        \n",
    "        ind = top.index(r)\n",
    "        for i, h in enumerate(how_many):\n",
    "            if ind < h:\n",
    "                hit[i] += 1\n",
    "        hit[3] += 1 / (1 + ind)    \n",
    "        \n",
    "        iteration += 1\n",
    "        if iter_show:\n",
    "            if iteration % freq == 0:\n",
    "                print(hit[2] / iteration, hit[2], iteration)\n",
    "            \n",
    "    return hit[0] / total, hit[1] / total, hit[2] / total, hit[3] / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('/notebook/wikidata_tensor/embeddings_tucker_als/embedding_size_variation/200/u0_200_237.npz.npy')\n",
    "b = np.load('/notebook/wikidata_tensor/embeddings_tucker_als/embedding_size_variation/200/u1_200_237.npz.npy')\n",
    "c = np.load('/notebook/wikidata_tensor/embeddings_tucker_als/embedding_size_variation/200/u2_200_237.npz.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "shape = (100, 100, 100)\n",
    "coo, vals = gen_coo_tensor(init_shape, density=0.02)\n",
    "assert check_coo_tensor(coo)!= \"Bad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 20\n",
    "rank = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "a, b, c, err, it = gcp_gd(\n",
    "    coo, vals, shape,\n",
    "    bernoulli_logit_loss,\n",
    "    bernoulli_logit_loss_grad,\n",
    "    rank=rank,\n",
    "    lr=0.1,\n",
    "    l2=0,\n",
    "    max_iter=max_iter,\n",
    "    tol=1e-8,\n",
    "    seed=13,\n",
    "    show_iter=False,\n",
    "    it_over=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Relative error\")\n",
    "plt.title(f\"Random tensor / CP-ALS3(R={rank})\")\n",
    "#plt.xticks(np.arange(max_iter))\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(np.arange(max_iter), err[:max_iter], 'g-*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CP-ALS3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "max_iter = 20\n",
    "rank = 3\n",
    "a, b, c, err, it = cp.cp_als3(coo, vals, shape, rank=rank, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Relative error\")\n",
    "plt.title(f\"Random tensor / CP-ALS3(R={rank})\")\n",
    "#plt.xticks(np.arange(max_iter))\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(np.arange(max_iter), err[:max_iter], 'g-*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
