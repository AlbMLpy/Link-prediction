{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from ipypb import track\n",
    "\n",
    "from general_functions1 import sqrt_err_relative, check_coo_tensor, gen_coo_tensor\n",
    "from general_functions1 import create_filter, hr\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/notebook/Relations_Learning/\") \n",
    "import CP_ALS3.CP_ALS3 as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebook/Relations_Learning/gpu\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/notebook/Relations_Learning/test_filter.pkl', 'rb') as f:\n",
    "    test_filter = pickle.load(f)\n",
    "    \n",
    "with open('/notebook/Relations_Learning/valid_filter.pkl', 'rb') as f:\n",
    "    valid_filter = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from t_alg import mttcrp, mttcrp1, get_elem_deriv_tensor, factors_to_tensor, gcp_grad, multi_ind_to_indices, indices_to_multi_ind\n",
    "\n",
    "from samplings import give_ns, generate_data\n",
    "\n",
    "from elementwise_grads import bernoulli_logit_loss, bernoulli_logit_loss_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17535"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "device=torch.device(\"cuda:4\")\n",
    "\n",
    "class GSP_SGD(torch.nn.Module):\n",
    "    def __init__(self, num_ent, num_rel, dim_emb, shape, loss_function, loss_function_grad):\n",
    "        super(GSP_SGD, self).__init__()\n",
    "                \n",
    "        self.ent = torch.empty((num_ent, dim_emb), device = device)\n",
    "        xavier_normal_(a_torch)\n",
    "        a_torch.requires_grad=True\n",
    "\n",
    "        self.rel = torch.empty((num_rel, dim_emb), device = device)\n",
    "        xavier_normal_(b_torch)\n",
    "        b_torch.requires_grad=True\n",
    "        \n",
    "        self.optimizer = optim.Adam([a_torch, b_torch, c_torch], lr=1e-3)\n",
    "        \n",
    "        self.coo = coo_tensor\n",
    "        self.vals = vals\n",
    "        self.shape = shape\n",
    "        self.elemwise_loss = loss_function\n",
    "        self.elemwise_grad = loss_function_grad\n",
    "\n",
    "        #c_torch = torch.empty((num_ent, dim_emb), device = device)\n",
    "        #xavier_normal_(c_torch)\n",
    "        #c_torch.requires_grad=True\n",
    "    \n",
    "    def forward(self, ent_idx, rel_idx):\n",
    "        pass\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gcp_grad(coo, val, shape, a, b, l2, loss_function, loss_function_grad, device):\n",
    "    \"\"\"\n",
    "        GCP loss function and gradient calculation.\n",
    "        All the tensors have the same coordinate set: coo_tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    # Construct sparse kruskal tensor\n",
    "    kruskal_val = torch.sum((a[coo[:,0], :] * b[coo[:,1], :] * a[coo[:,2], :]),1)\n",
    "    #factors_to_tensor(coo_tensor, vals, a, b, c)\n",
    "    \n",
    "    # Calculate mean loss on known entries\n",
    "    loss = loss_function(val, kruskal_val)\n",
    "    # Compute the elementwise derivative tensor\n",
    "    deriv_tensor_val = loss_function_grad(val, kruskal_val)\n",
    "    \n",
    "    #print (\"in qcp_grad in deriv_tensor_val \", deriv_tensor_val)\n",
    "    # Calculate gradients w.r.t. a, b, c factor matrices\n",
    "    g_a = mttcrp1(coo, deriv_tensor_val, shape, 0, b, a, device)\n",
    "    g_b = mttcrp1(coo, deriv_tensor_val, shape, 1, a, a, device)\n",
    "    g_c = mttcrp1(coo, deriv_tensor_val, shape, 2, a, b, device)\n",
    "    \n",
    "    #print (\"\\n\\n\")\n",
    "    \n",
    "    \n",
    "    # Add L2 regularization\n",
    "    if l2 != 0:\n",
    "        g_a += l2 * a[coo[0], :]\n",
    "        g_b += l2 * b[coo[1], :]\n",
    "        g_c += l2 * c[coo[2], :]\n",
    "    \n",
    "    return loss, g_a, g_b, g_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('/notebook/Relations_Learning/a200.npz', a)\n",
    "#np.save('/notebook/Relations_Learning/b200.npz', b)\n",
    "#np.save('/notebook/Relations_Learning/c200.npz', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d74f1bcdd37c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/notebook/Relations_Learning/results/gpu_a.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-4302d69244ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/notebook/Relations_Learning/results/gpu_a.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/notebook/Relations_Learning/results/gpu_b.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/notebook/Relations_Learning/results/gpu_c.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/notebook/Relations_Learning/results/gpu_a.npz'"
     ]
    }
   ],
   "source": [
    "a = np.load('/notebook/Relations_Learning/results/gpu_a.npz')\n",
    "b = np.load('/notebook/Relations_Learning/results/gpu_b.npz')\n",
    "c = np.load('/notebook/Relations_Learning/results/gpu_c.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"/notebook/Relations_Learning/Link_Prediction_Data/FB15K237/\"\n",
    "entity_list = pickle.load(open(path_data + 'entity_list', 'rb'))\n",
    "relation_list = pickle.load(open(path_data + 'relation_list', 'rb'))\n",
    "\n",
    "train_triples = pickle.load(open(path_data + 'train_triples', 'rb'))\n",
    "valid_triples = pickle.load(open(path_data + 'valid_triples', 'rb'))\n",
    "test_triples = pickle.load(open(path_data + 'test_triples', 'rb'))\n",
    "train_valid_triples = pickle.load(open(path_data + 'train_valid_triples', 'rb'))\n",
    "\n",
    "entity_map = pickle.load(open(path_data + 'entity_map', 'rb'))\n",
    "relation_map = pickle.load(open(path_data + 'relation_map', 'rb'))\n",
    "\n",
    "all_triples = train_valid_triples + test_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272115"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_filter = create_filter(test_triples, all_triples)\n",
    "#train_filter = create_filter(train_triples, all_triples)  \n",
    "#valid_filter = create_filter(valid_triples, all_triples)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('train_filter.pkl', 'wb') as handle:\n",
    "    #pickle.dump(train_filter, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/notebook/Relations_Learning/test_filter.pkl', 'rb') as f:\n",
    "    test_filter = pickle.load(f)\n",
    "    \n",
    "with open('/notebook/Relations_Learning/valid_filter.pkl', 'rb') as f:\n",
    "    valid_filter = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14541, 237, 14541)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = [1] * len(train_triples)\n",
    "values = np.array(values, dtype=np.int64)\n",
    "\n",
    "coords = np.array(train_triples, dtype=np.int64)\n",
    "nnz = len(train_triples)\n",
    "data_shape = (len(entity_list), len(relation_list), len(entity_list))\n",
    "data_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 1000 \n",
    "rank = 100 \n",
    "l2 =  0\n",
    "lr = 1e-2 \n",
    "seed = 13 \n",
    "hm = 1000\n",
    "how_many = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 17 11:17:54 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.03   Driver Version: 450.119.03   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 49%   55C    P2    92W / 260W |  10769MiB / 11019MiB |     38%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 27%   28C    P8     9W / 260W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:1C:00.0 Off |                  N/A |\n",
      "| 27%   35C    P8     5W / 260W |   1678MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   31C    P8    12W / 260W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  Off  | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 29%   43C    P2    51W / 260W |   1264MiB / 11019MiB |     11%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  Off  | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 92%   82C    P2   255W / 260W |   9780MiB / 11019MiB |     97%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  Off  | 00000000:40:00.0 Off |                  N/A |\n",
      "| 83%   75C    P2   257W / 260W |   9780MiB / 11019MiB |     98%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  Off  | 00000000:41:00.0 Off |                  N/A |\n",
      "| 71%   68C    P2   256W / 260W |   9780MiB / 11019MiB |     97%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'err_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2445ec064380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0merr_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'err_list' is not defined"
     ]
    }
   ],
   "source": [
    "err_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816345 56 14577\n",
      "Iter:  0 ; Error:  0.693148894818153\n",
      "Iter:  500 ; Error:  0.69314263059847\n",
      "Iter:  1000 ; Error:  0.6931275208894371\n",
      "Iter:  1500 ; Error:  0.6929910406011528\n",
      "Iter:  2000 ; Error:  0.6923908214804464\n",
      "Iter:  2500 ; Error:  0.6909919566676213\n",
      "Iter:  3000 ; Error:  0.6884917191670885\n",
      "Iter:  3500 ; Error:  0.6850760894281359\n",
      "Iter:  4000 ; Error:  0.6806025056353978\n",
      "Iter:  4500 ; Error:  0.6753652818623903\n",
      "Iter:  5000 ; Error:  0.6693285032459815\n",
      "Iter:  5500 ; Error:  0.6630022582332332\n",
      "Iter:  6000 ; Error:  0.6565179085686974\n",
      "Iter:  6500 ; Error:  0.6499275172772213\n",
      "Iter:  7000 ; Error:  0.6434701872471795\n",
      "Iter:  7500 ; Error:  0.6372392063743079\n",
      "Iter:  8000 ; Error:  0.6309763117352207\n",
      "Iter:  8500 ; Error:  0.6248531821520925\n",
      "Iter:  9000 ; Error:  0.6188570727238765\n",
      "Iter:  9500 ; Error:  0.6129146917255622\n",
      "Iter:  10000 ; Error:  0.607031464692191\n",
      "Iter:  10500 ; Error:  0.601064645532582\n",
      "Iter:  11000 ; Error:  0.5946090584886854\n",
      "Iter:  11500 ; Error:  0.5878414596668963\n",
      "Iter:  12000 ; Error:  0.5802827890725729\n",
      "Iter:  12500 ; Error:  0.571974629128398\n",
      "Iter:  13000 ; Error:  0.5627410866199843\n",
      "Iter:  13500 ; Error:  0.5527251299501397\n",
      "Iter:  14000 ; Error:  0.5420329890115784\n",
      "Iter:  14500 ; Error:  0.5309354103026095\n",
      "count hr\n",
      "(0.221, 0.299, 0.433, 0.28792747063934104)\n",
      "425.60572102700826\n",
      "816345 56 14577\n",
      "Iter:  14577 ; Error:  0.21705713043255465\n",
      "Iter:  15077 ; Error:  0.18402048218393008\n",
      "Iter:  15577 ; Error:  0.1736811936595484\n",
      "Iter:  16077 ; Error:  0.1634833910918481\n",
      "Iter:  16577 ; Error:  0.15411597595841825\n",
      "Iter:  17077 ; Error:  0.14656181311986122\n",
      "Iter:  17577 ; Error:  0.1401101268421075\n",
      "Iter:  18077 ; Error:  0.13482356216338726\n",
      "Iter:  18577 ; Error:  0.1297951934523026\n",
      "Iter:  19077 ; Error:  0.12513212720286085\n",
      "Iter:  19577 ; Error:  0.12116348406368031\n",
      "Iter:  20077 ; Error:  0.11751843991577918\n",
      "Iter:  20577 ; Error:  0.11410016132058302\n",
      "Iter:  21077 ; Error:  0.1109065021133091\n",
      "Iter:  21577 ; Error:  0.1079899007760227\n",
      "Iter:  22077 ; Error:  0.10516335673104502\n",
      "Iter:  22577 ; Error:  0.10247716963090818\n",
      "Iter:  23077 ; Error:  0.09998290045081752\n",
      "Iter:  23577 ; Error:  0.09772746348235313\n",
      "Iter:  24077 ; Error:  0.09565559463570912\n",
      "Iter:  24577 ; Error:  0.09362148429768254\n",
      "Iter:  25077 ; Error:  0.09165686441665502\n",
      "Iter:  25577 ; Error:  0.08989138035370128\n",
      "Iter:  26077 ; Error:  0.08823793890641761\n",
      "Iter:  26577 ; Error:  0.08663858774871697\n",
      "Iter:  27077 ; Error:  0.08518694953875872\n",
      "Iter:  27577 ; Error:  0.08372357579807962\n",
      "Iter:  28077 ; Error:  0.08231526062571488\n",
      "Iter:  28577 ; Error:  0.08084866478954114\n",
      "Iter:  29077 ; Error:  0.07941672948829664\n",
      "count hr\n",
      "(0.23, 0.328, 0.474, 0.3087030963446296)\n",
      "852.4039621859847\n",
      "816345 56 14577\n",
      "Iter:  29154 ; Error:  0.007686374229403928\n",
      "Iter:  29654 ; Error:  0.02951577970805252\n",
      "Iter:  30154 ; Error:  0.029982932903421855\n",
      "Iter:  30654 ; Error:  0.029101240416190458\n",
      "Iter:  31154 ; Error:  0.028652378591150274\n",
      "Iter:  31654 ; Error:  0.028310643600469487\n",
      "Iter:  32154 ; Error:  0.02815769527744761\n",
      "Iter:  32654 ; Error:  0.0281566312428563\n",
      "Iter:  33154 ; Error:  0.027725510379525063\n",
      "Iter:  33654 ; Error:  0.02770787207403948\n",
      "Iter:  34154 ; Error:  0.02762553773144722\n",
      "Iter:  34654 ; Error:  0.027276725091109157\n",
      "Iter:  35154 ; Error:  0.027119320959979338\n",
      "Iter:  35654 ; Error:  0.026722401728018815\n",
      "Iter:  36154 ; Error:  0.026415184006944786\n",
      "Iter:  36654 ; Error:  0.026312672005252374\n",
      "Iter:  37154 ; Error:  0.026135718913476436\n",
      "Iter:  37654 ; Error:  0.02593043615526773\n",
      "Iter:  38154 ; Error:  0.02567058127811627\n",
      "Iter:  38654 ; Error:  0.025473254981225393\n",
      "Iter:  39154 ; Error:  0.025214811241752694\n",
      "Iter:  39654 ; Error:  0.02493261840845406\n",
      "Iter:  40154 ; Error:  0.0248070758845388\n",
      "Iter:  40654 ; Error:  0.02474344266295465\n",
      "Iter:  41154 ; Error:  0.024541759829761728\n",
      "Iter:  41654 ; Error:  0.02426896273298923\n",
      "Iter:  42154 ; Error:  0.024141831401076588\n",
      "Iter:  42654 ; Error:  0.02399274405951114\n",
      "Iter:  43154 ; Error:  0.023830643420741576\n",
      "Iter:  43654 ; Error:  0.023641116026785387\n",
      "count hr\n",
      "(0.201, 0.332, 0.462, 0.29197817627360634)\n",
      "1248.5726376659877\n",
      "816345 56 14577\n",
      "Iter:  43731 ; Error:  0.004933277474042644\n",
      "Iter:  44231 ; Error:  0.01595294844741293\n",
      "Iter:  44731 ; Error:  0.014337243167144737\n",
      "Iter:  45231 ; Error:  0.014497649959589135\n",
      "Iter:  45731 ; Error:  0.014461937779107162\n",
      "Iter:  46231 ; Error:  0.013805828049535803\n",
      "Iter:  46731 ; Error:  0.013748035290066104\n",
      "Iter:  47231 ; Error:  0.013587909440570766\n",
      "Iter:  47731 ; Error:  0.013296567614505957\n",
      "Iter:  48231 ; Error:  0.013213941445629561\n",
      "Iter:  48731 ; Error:  0.01317947060969038\n",
      "Iter:  49231 ; Error:  0.013046245731787861\n",
      "Iter:  49731 ; Error:  0.013023924323339918\n",
      "Iter:  50231 ; Error:  0.013007355756426852\n",
      "Iter:  50731 ; Error:  0.013184552700526606\n",
      "Iter:  51231 ; Error:  0.01316010478150241\n",
      "Iter:  51731 ; Error:  0.013047881908237352\n",
      "Iter:  52231 ; Error:  0.01314531655252534\n",
      "Iter:  52731 ; Error:  0.013069103908593945\n",
      "Iter:  53231 ; Error:  0.01311204813874614\n",
      "Iter:  53731 ; Error:  0.013137672092324833\n",
      "Iter:  54231 ; Error:  0.0130841169923141\n",
      "Iter:  54731 ; Error:  0.013122174787829543\n",
      "Iter:  55231 ; Error:  0.013165423055534128\n",
      "Iter:  55731 ; Error:  0.013122538692939388\n",
      "Iter:  56231 ; Error:  0.013057296653513196\n",
      "Iter:  56731 ; Error:  0.012977995763369821\n",
      "Iter:  57231 ; Error:  0.012904540253063292\n",
      "Iter:  57731 ; Error:  0.01294627282262916\n",
      "Iter:  58231 ; Error:  0.01300241219895341\n",
      "count hr\n",
      "(0.198, 0.295, 0.455, 0.27963979622416385)\n",
      "1639.124016518006\n",
      "816345 56 14577\n",
      "Iter:  58308 ; Error:  0.06416282057568205\n",
      "Iter:  58808 ; Error:  0.00935199510830446\n",
      "Iter:  59308 ; Error:  0.00915016153826802\n",
      "Iter:  59808 ; Error:  0.008608699312136035\n",
      "Iter:  60308 ; Error:  0.008374283721958082\n",
      "Iter:  60808 ; Error:  0.008558399667026886\n",
      "Iter:  61308 ; Error:  0.008546355600678457\n",
      "Iter:  61808 ; Error:  0.008831804727684266\n",
      "Iter:  62308 ; Error:  0.008754913935043527\n",
      "Iter:  62808 ; Error:  0.008513661160533937\n",
      "Iter:  63308 ; Error:  0.008844989316610714\n",
      "Iter:  63808 ; Error:  0.008879992776369751\n",
      "Iter:  64308 ; Error:  0.008752771680865998\n",
      "Iter:  64808 ; Error:  0.00865427358099309\n",
      "Iter:  65308 ; Error:  0.008653882280064655\n",
      "Iter:  65808 ; Error:  0.008601792529036301\n",
      "Iter:  66308 ; Error:  0.008583347841339807\n",
      "Iter:  66808 ; Error:  0.008682011744799533\n",
      "Iter:  67308 ; Error:  0.00877044416825034\n",
      "Iter:  67808 ; Error:  0.008733913669698716\n",
      "Iter:  68308 ; Error:  0.008760269294054044\n",
      "Iter:  68808 ; Error:  0.00871592277959079\n",
      "Iter:  69308 ; Error:  0.008684803461101268\n",
      "Iter:  69808 ; Error:  0.008666249569908843\n",
      "Iter:  70308 ; Error:  0.008584188963213064\n",
      "Iter:  70808 ; Error:  0.008590128754882777\n",
      "Iter:  71308 ; Error:  0.008553576732080428\n",
      "Iter:  71808 ; Error:  0.008533599056879877\n",
      "Iter:  72308 ; Error:  0.008524823526587047\n",
      "Iter:  72808 ; Error:  0.008517252525103415\n",
      "count hr\n",
      "(0.193, 0.303, 0.456, 0.2797059587602171)\n",
      "2028.480459724\n",
      "816345 56 14577\n",
      "Iter:  72885 ; Error:  0.0005221578102434827\n",
      "Iter:  73385 ; Error:  0.005660670988776564\n",
      "Iter:  73885 ; Error:  0.0066890226609322345\n",
      "Iter:  74385 ; Error:  0.006824408713557684\n",
      "Iter:  74885 ; Error:  0.007064414410559694\n",
      "Iter:  75385 ; Error:  0.0065749627573765705\n",
      "Iter:  75885 ; Error:  0.006603481827613931\n",
      "Iter:  76385 ; Error:  0.006546785151345924\n",
      "Iter:  76885 ; Error:  0.006521597968143581\n",
      "Iter:  77385 ; Error:  0.006903438756319462\n",
      "Iter:  77885 ; Error:  0.006786954149387743\n",
      "Iter:  78385 ; Error:  0.006943848261422674\n",
      "Iter:  78885 ; Error:  0.007004588861834857\n",
      "Iter:  79385 ; Error:  0.006864524165868661\n",
      "Iter:  79885 ; Error:  0.0068470508923123945\n",
      "Iter:  80385 ; Error:  0.006812421090006733\n",
      "Iter:  80885 ; Error:  0.006799844341312674\n",
      "Iter:  81385 ; Error:  0.006896302191138702\n",
      "Iter:  81885 ; Error:  0.006912567413001267\n",
      "Iter:  82385 ; Error:  0.006875462159061822\n",
      "Iter:  82885 ; Error:  0.0068606828809552045\n",
      "Iter:  83385 ; Error:  0.006848281802513536\n",
      "Iter:  83885 ; Error:  0.006863325219059548\n",
      "Iter:  84385 ; Error:  0.006759017301575936\n",
      "Iter:  84885 ; Error:  0.0068268551369217575\n",
      "Iter:  85385 ; Error:  0.006802749961291463\n",
      "Iter:  85885 ; Error:  0.006792328221149801\n",
      "Iter:  86385 ; Error:  0.006850998613062124\n",
      "Iter:  86885 ; Error:  0.006825409796525938\n",
      "Iter:  87385 ; Error:  0.006857028632994161\n",
      "count hr\n",
      "(0.194, 0.302, 0.459, 0.2797809293703776)\n",
      "2449.4116047490097\n",
      "816345 56 14577\n",
      "Iter:  87462 ; Error:  0.0001076823350878442\n",
      "Iter:  87962 ; Error:  0.006988169489087888\n",
      "Iter:  88462 ; Error:  0.006650276679439978\n",
      "Iter:  88962 ; Error:  0.006742026149820076\n",
      "Iter:  89462 ; Error:  0.0063210643837227475\n",
      "Iter:  89962 ; Error:  0.006176653770033469\n",
      "Iter:  90462 ; Error:  0.00603615203996658\n",
      "Iter:  90962 ; Error:  0.005933585378505068\n",
      "Iter:  91462 ; Error:  0.006008195226463066\n",
      "Iter:  91962 ; Error:  0.006092290063740224\n",
      "Iter:  92462 ; Error:  0.00599397203748947\n",
      "Iter:  92962 ; Error:  0.0059022630851974555\n",
      "Iter:  93462 ; Error:  0.006015219441580525\n",
      "Iter:  93962 ; Error:  0.00592174101540788\n",
      "Iter:  94462 ; Error:  0.005992394741231135\n",
      "Iter:  94962 ; Error:  0.006063689642268104\n",
      "Iter:  95462 ; Error:  0.006059604847126606\n",
      "Iter:  95962 ; Error:  0.006038570564226893\n",
      "Iter:  96462 ; Error:  0.005978834534603613\n",
      "Iter:  96962 ; Error:  0.006096195991820125\n",
      "Iter:  97462 ; Error:  0.00609787519649781\n",
      "Iter:  97962 ; Error:  0.006163615942799579\n",
      "Iter:  98462 ; Error:  0.006089627905855451\n",
      "Iter:  98962 ; Error:  0.0060392580299920805\n",
      "Iter:  99462 ; Error:  0.00608182844572407\n",
      "Iter:  99962 ; Error:  0.006141764396265655\n",
      "Iter:  100462 ; Error:  0.006256870315201597\n",
      "Iter:  100962 ; Error:  0.006293153063463447\n",
      "Iter:  101462 ; Error:  0.006304780342080426\n",
      "Iter:  101962 ; Error:  0.006329948038605116\n",
      "count hr\n",
      "(0.182, 0.288, 0.426, 0.2646427508185971)\n",
      "2874.1347039930115\n",
      "816345 56 14577\n",
      "Iter:  102039 ; Error:  0.00012825286771572003\n",
      "Iter:  102539 ; Error:  0.006011605660877149\n",
      "Iter:  103039 ; Error:  0.005513662889314843\n",
      "Iter:  103539 ; Error:  0.005129880473939946\n",
      "Iter:  104039 ; Error:  0.005374754560455122\n",
      "Iter:  104539 ; Error:  0.004901681166073525\n",
      "Iter:  105039 ; Error:  0.004959484119681169\n",
      "Iter:  105539 ; Error:  0.004934033068541163\n",
      "Iter:  106039 ; Error:  0.0051380198665428554\n",
      "Iter:  106539 ; Error:  0.0050047535519753905\n",
      "Iter:  107039 ; Error:  0.005085215596680427\n",
      "Iter:  107539 ; Error:  0.005065599537731366\n",
      "Iter:  108039 ; Error:  0.005101000083705113\n",
      "Iter:  108539 ; Error:  0.005059051747379013\n",
      "Iter:  109039 ; Error:  0.005022961440546912\n",
      "Iter:  109539 ; Error:  0.005064200984676662\n",
      "Iter:  110039 ; Error:  0.004984784295027858\n",
      "Iter:  110539 ; Error:  0.005024486466510706\n",
      "Iter:  111039 ; Error:  0.005077122319496229\n",
      "Iter:  111539 ; Error:  0.005069176518818248\n",
      "Iter:  112039 ; Error:  0.005150184883857272\n",
      "Iter:  112539 ; Error:  0.005165511559997487\n",
      "Iter:  113039 ; Error:  0.0052834086631982705\n",
      "Iter:  113539 ; Error:  0.00529054226628148\n",
      "Iter:  114039 ; Error:  0.005277108462439737\n",
      "Iter:  114539 ; Error:  0.005223386882281237\n",
      "Iter:  115039 ; Error:  0.005240097573397835\n",
      "Iter:  115539 ; Error:  0.005253338361888036\n",
      "Iter:  116039 ; Error:  0.005289314639730855\n",
      "Iter:  116539 ; Error:  0.005266052750085616\n",
      "count hr\n",
      "(0.175, 0.286, 0.432, 0.2619829315452675)\n",
      "3291.3141114309838\n",
      "816345 56 14577\n",
      "Iter:  116616 ; Error:  6.421872458910778e-05\n",
      "Iter:  117116 ; Error:  0.0067854404666779404\n",
      "Iter:  117616 ; Error:  0.005058563037087507\n",
      "Iter:  118116 ; Error:  0.005114991020429823\n",
      "Iter:  118616 ; Error:  0.004861834127343837\n",
      "Iter:  119116 ; Error:  0.005221713489919381\n",
      "Iter:  119616 ; Error:  0.005225082177394714\n",
      "Iter:  120116 ; Error:  0.005198977288006291\n",
      "Iter:  120616 ; Error:  0.005183206481365942\n",
      "Iter:  121116 ; Error:  0.00504489422684981\n",
      "Iter:  121616 ; Error:  0.005048488462864453\n",
      "Iter:  122116 ; Error:  0.005023460532105702\n",
      "Iter:  122616 ; Error:  0.005102908490689328\n",
      "Iter:  123116 ; Error:  0.005145737161347125\n",
      "Iter:  123616 ; Error:  0.0050744064194339095\n",
      "Iter:  124116 ; Error:  0.004997656858397871\n",
      "Iter:  124616 ; Error:  0.004947333195078514\n",
      "Iter:  125116 ; Error:  0.004849121265244006\n",
      "Iter:  125616 ; Error:  0.004893021833440928\n",
      "Iter:  126116 ; Error:  0.004985723133891051\n",
      "Iter:  126616 ; Error:  0.004989184330222684\n",
      "Iter:  127116 ; Error:  0.004991684858388923\n",
      "Iter:  127616 ; Error:  0.004890151282118139\n",
      "Iter:  128116 ; Error:  0.0050128170437508945\n",
      "Iter:  128616 ; Error:  0.004992348452010411\n",
      "Iter:  129116 ; Error:  0.004997716028248277\n",
      "Iter:  129616 ; Error:  0.004941785413339488\n",
      "Iter:  130116 ; Error:  0.00491212941351579\n",
      "Iter:  130616 ; Error:  0.00493128148853316\n",
      "Iter:  131116 ; Error:  0.004941238703684477\n",
      "count hr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebook/Relations_Learning/gpu/general_functions1.py:36: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.163, 0.267, 0.434, 0.250173139125795)\n",
      "3699.8518598749943\n",
      "816345 56 14577\n",
      "Iter:  131193 ; Error:  6.765948323460082e-05\n",
      "Iter:  131693 ; Error:  0.004784347421054029\n",
      "Iter:  132193 ; Error:  0.0058706050562521385\n",
      "Iter:  132693 ; Error:  0.005674927713533042\n",
      "Iter:  133193 ; Error:  0.0055823786730217345\n",
      "Iter:  133693 ; Error:  0.005211527608840046\n",
      "Iter:  134193 ; Error:  0.005133393598387257\n",
      "Iter:  134693 ; Error:  0.005308701204495812\n",
      "Iter:  135193 ; Error:  0.005054439108150128\n",
      "Iter:  135693 ; Error:  0.004895187510930561\n",
      "Iter:  136193 ; Error:  0.005014179623888938\n",
      "Iter:  136693 ; Error:  0.005015759923947803\n",
      "Iter:  137193 ; Error:  0.004964002316659264\n",
      "Iter:  137693 ; Error:  0.004860302661969331\n",
      "Iter:  138193 ; Error:  0.004820514250714166\n",
      "Iter:  138693 ; Error:  0.004832278984204171\n",
      "Iter:  139193 ; Error:  0.004698070415248429\n",
      "Iter:  139693 ; Error:  0.0047416568004099375\n",
      "Iter:  140193 ; Error:  0.004753843092683729\n",
      "Iter:  140693 ; Error:  0.00471149925014986\n",
      "Iter:  141193 ; Error:  0.00467922952438124\n",
      "Iter:  141693 ; Error:  0.004629277654217532\n",
      "Iter:  142193 ; Error:  0.004717716273833811\n",
      "Iter:  142693 ; Error:  0.004712060663130949\n",
      "Iter:  143193 ; Error:  0.004688549291969486\n",
      "Iter:  143693 ; Error:  0.004793420773334002\n",
      "Iter:  144193 ; Error:  0.004840374627416244\n",
      "Iter:  144693 ; Error:  0.004796155452986243\n",
      "Iter:  145193 ; Error:  0.00476708420923676\n",
      "Iter:  145693 ; Error:  0.004729703184407393\n",
      "count hr\n",
      "(0.178, 0.271, 0.412, 0.2532061811829088)\n",
      "4104.053733284003\n",
      "816345 56 14577\n",
      "Iter:  145770 ; Error:  3.153411692607173e-05\n",
      "Iter:  146270 ; Error:  0.004502706886744285\n",
      "Iter:  146770 ; Error:  0.004804686377108231\n",
      "Iter:  147270 ; Error:  0.004371026539724277\n",
      "Iter:  147770 ; Error:  0.004483326204448653\n",
      "Iter:  148270 ; Error:  0.004423078685544496\n",
      "Iter:  148770 ; Error:  0.004323989907702912\n",
      "Iter:  149270 ; Error:  0.004148547570318123\n",
      "Iter:  149770 ; Error:  0.004384664753530585\n",
      "Iter:  150270 ; Error:  0.004442046055111336\n",
      "Iter:  150770 ; Error:  0.004389969750793808\n",
      "Iter:  151270 ; Error:  0.004619902205335232\n",
      "Iter:  151770 ; Error:  0.004608086493586384\n",
      "Iter:  152270 ; Error:  0.004516358297401207\n",
      "Iter:  152770 ; Error:  0.004538065610557658\n",
      "Iter:  153270 ; Error:  0.004445034217077999\n",
      "Iter:  153770 ; Error:  0.004565205263140201\n",
      "Iter:  154270 ; Error:  0.004482135419519179\n",
      "Iter:  154770 ; Error:  0.004541818215464938\n",
      "Iter:  155270 ; Error:  0.004603981110461691\n",
      "Iter:  155770 ; Error:  0.004616815397227154\n",
      "Iter:  156270 ; Error:  0.0045638078161438595\n",
      "Iter:  156770 ; Error:  0.004569169135574913\n",
      "Iter:  157270 ; Error:  0.004609674903122723\n",
      "Iter:  157770 ; Error:  0.004529219266205094\n",
      "Iter:  158270 ; Error:  0.0045958640583141554\n",
      "Iter:  158770 ; Error:  0.0045784259375030835\n",
      "Iter:  159270 ; Error:  0.004611437863436018\n",
      "Iter:  159770 ; Error:  0.004613074974022695\n",
      "Iter:  160270 ; Error:  0.004680678500624243\n",
      "count hr\n",
      "(0.164, 0.26, 0.408, 0.2471138394888294)\n",
      "4519.490255373006\n",
      "816345 56 14577\n",
      "Iter:  160347 ; Error:  8.559824930922031e-05\n",
      "Iter:  160847 ; Error:  0.003309335746202667\n",
      "Iter:  161347 ; Error:  0.003695518745165776\n",
      "Iter:  161847 ; Error:  0.0037132518690932335\n",
      "Iter:  162347 ; Error:  0.003726652866289406\n",
      "Iter:  162847 ; Error:  0.003859283534753007\n",
      "Iter:  163347 ; Error:  0.004310829811104034\n",
      "Iter:  163847 ; Error:  0.00421540850669842\n",
      "Iter:  164347 ; Error:  0.004183738995875938\n",
      "Iter:  164847 ; Error:  0.004202949948565091\n",
      "Iter:  165347 ; Error:  0.004213067673504029\n",
      "Iter:  165847 ; Error:  0.00415891991806852\n",
      "Iter:  166347 ; Error:  0.004208861649052491\n",
      "Iter:  166847 ; Error:  0.004235959278120778\n",
      "Iter:  167347 ; Error:  0.00427177691259925\n",
      "Iter:  167847 ; Error:  0.0043262847847658804\n",
      "Iter:  168347 ; Error:  0.0043940489590945375\n",
      "Iter:  168847 ; Error:  0.004333009339924547\n",
      "Iter:  169347 ; Error:  0.004227947123618614\n",
      "Iter:  169847 ; Error:  0.004125825348917705\n",
      "Iter:  170347 ; Error:  0.004118471171128569\n",
      "Iter:  170847 ; Error:  0.004047175939046613\n",
      "Iter:  171347 ; Error:  0.004015574970751672\n",
      "Iter:  171847 ; Error:  0.003982668764530117\n",
      "Iter:  172347 ; Error:  0.0040203250203274974\n",
      "Iter:  172847 ; Error:  0.004013963933380093\n",
      "Iter:  173347 ; Error:  0.00411396687963978\n",
      "Iter:  173847 ; Error:  0.004173108414673654\n",
      "Iter:  174347 ; Error:  0.004189842589612422\n",
      "Iter:  174847 ; Error:  0.0041787029031040285\n",
      "count hr\n",
      "(0.171, 0.267, 0.413, 0.2513501880221201)\n",
      "4995.785231380985\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "coo_tensor = coords\n",
    "vals = values\n",
    "shape = data_shape\n",
    "loss_function = bernoulli_logit_loss\n",
    "loss_function_grad = bernoulli_logit_loss_grad\n",
    "\n",
    "from torch.nn.init import xavier_normal_\n",
    "from torch import optim\n",
    "\n",
    "device=torch.device(\"cuda:4\")\n",
    "\n",
    "num_epoch = 12\n",
    "\n",
    "random_state = np.random.seed(seed)\n",
    "\n",
    "batch_size = 56\n",
    "init_mind_set = set(indices_to_multi_ind(coo_tensor, shape))\n",
    "coo_ns = np.empty((how_many * len(init_mind_set) + vals.size, 3), dtype=np.int64)\n",
    "vals_ns = np.empty((how_many * len(init_mind_set) + vals.size,), dtype=np.float64)\n",
    "\n",
    "err_arr = np.empty((num_epoch*vals_ns.shape[0]//batch_size + 1, ), dtype=np.float64)\n",
    "error = 0.0\n",
    "it = 0\n",
    "\n",
    "num_ent = 14541\n",
    "dim_emb = 200\n",
    "num_rel = 237\n",
    "\n",
    "a_torch = torch.empty((num_ent, dim_emb), requires_grad = True, device = device)\n",
    "xavier_normal_(a_torch)\n",
    "a_torch.grad = torch.zeros(a_torch.shape, device = device)\n",
    "\n",
    "b_torch = torch.empty((num_rel, dim_emb), requires_grad = True, device = device)\n",
    "xavier_normal_(b_torch)\n",
    "b_torch.grad = torch.zeros(b_torch.shape, device = device)\n",
    "\n",
    "optimizer = optim.Adam([a_torch, b_torch], lr=1e-3)\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "\n",
    "show_iter = True\n",
    "\n",
    "start = timer()\n",
    "for epoch in range(num_epoch):\n",
    "    coo_ns, vals_ns = generate_data(coo_tensor, vals, init_mind_set, shape, how_many, epoch)\n",
    "    coo_ns = torch.tensor(coo_ns, device = device)\n",
    "    vals_ns = torch.tensor(vals_ns, device = device)\n",
    "    shuffler = np.random.permutation(vals_ns.shape[0])\n",
    "    coo_ns = coo_ns[shuffler]\n",
    "    vals_ns = vals_ns[shuffler]\n",
    "    #idxs = np.random.permutation(vals_ns.shape[0])\n",
    "    print (vals_ns.shape[0], batch_size, vals_ns.shape[0]//batch_size)\n",
    "    err_list = []\n",
    "    for i in range(vals_ns.shape[0]//batch_size):\n",
    "        # Get loss and gradients per sample\n",
    "        # print (\"coo_ns[i], vals_ns[i]\", coo_ns[i], vals_ns[i])\n",
    "        end = min(vals_ns.shape[0] - 1, (i+1)*batch_size)\n",
    "        loss, g_a, g_b, g_c = gcp_grad(\n",
    "            coo_ns[i*batch_size : end], vals_ns[i*batch_size : end], shape, a_torch, b_torch,\n",
    "            l2, loss_function, loss_function_grad, device\n",
    "        )\n",
    "        err_list.append(loss.cpu().detach().numpy().mean())\n",
    "\n",
    "        a_elems = coo_ns[i*batch_size : end, 0]\n",
    "        b_elems = coo_ns[i*batch_size : end, 1]\n",
    "        c_elems = coo_ns[i*batch_size : end, 2]\n",
    "        \n",
    "        a_torch.grad[a_elems, :] = g_a\n",
    "        b_torch.grad[b_elems, :] = g_b\n",
    "        a_torch.grad[c_elems, :] = g_c\n",
    "        optimizer.step()\n",
    "        a_torch.grad = torch.zeros(a_torch.shape, device = device)\n",
    "        b_torch.grad = torch.zeros(b_torch.shape, device = device)\n",
    "        \n",
    "        err_arr[it] = np.mean(err_list)\n",
    "        if show_iter and i%500 == 0:\n",
    "            print(\"Iter: \", it, \"; Error: \", np.mean(np.array(err_list)))\n",
    "        it += 1   \n",
    "    scheduler.step()\n",
    "    a = a_torch.cpu().data.numpy()\n",
    "    b = b_torch.cpu().data.numpy()\n",
    "    c = a_torch.cpu().data.numpy()\n",
    "    print (\"count hr\")\n",
    "    print (hr(valid_filter[:1000], valid_triples[:1000], a, b, c, [1, 3, 10]) )\n",
    "    end = timer()\n",
    "    print (end - start)\n",
    "    np.save('/notebook/Relations_Learning/results/gpu_a.npz', a_torch.cpu().data.numpy())\n",
    "    np.save('/notebook/Relations_Learning/results/gpu_b.npz', b_torch.cpu().data.numpy())\n",
    "    np.save('/notebook/Relations_Learning/results/gpu_c.npz', a_torch.cpu().data.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "\n",
    "a, b, c, err_arr, it = gcp_sgd_ns(\n",
    "    coords, values, data_shape,\n",
    "    bernoulli_logit_loss, \n",
    "    bernoulli_logit_loss_grad, \n",
    "    rank=rank,\n",
    "    lr=lr,\n",
    "    l2=l2,\n",
    "    num_epoch=num_epoch,\n",
    "    how_many=how_many,\n",
    "    seed=seed,\n",
    "    show_iter=True,\n",
    "    it_over=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "a, b, c, err_arr, it = gcp_sgd_ns(\n",
    "    coords, values, data_shape,\n",
    "    bernoulli_logit_loss, \n",
    "    bernoulli_logit_loss_grad, \n",
    "    rank=rank,\n",
    "    lr=lr,\n",
    "    l2=l2,\n",
    "    num_epoch=num_epoch,\n",
    "    how_many=how_many,\n",
    "    seed=seed,\n",
    "    show_iter=True,\n",
    "    it_over=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerr = sqrt_err_relative(\n",
    "    coords, values, data_shape, a, b, c,\n",
    ")\n",
    "print(f\"Relative error = {rerr}, {(np.isnan(a)).sum()}, {(np.isnan(b)).sum()}, {(np.isnan(c)).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Relative error\")\n",
    "plt.title(f\"FB15k-237 / GCP-GD3(R={rank}) G\")\n",
    "#plt.xticks(np.arange(it))\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(np.arange(1, it+1), err_arr[:it], '-*', c=\"#8b0a50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def safe_inverse_root(d, dtype=None):\n",
    "    pos_d = d > 0\n",
    "    res = np.zeros(len(d), dtype=dtype)\n",
    "    np.power(d, -0.5, where=pos_d, dtype=dtype, out=res)\n",
    "    return res\n",
    "\n",
    "def normalize_features(feature_mat, dtype=None):\n",
    "    sqsum = np.power(feature_mat, 2).sum(axis=1).view(type=np.ndarray).squeeze()\n",
    "    # avoid zero division\n",
    "    norm_data = safe_inverse_root(sqsum, dtype=dtype)\n",
    "    normed = scipy.sparse.diags(norm_data).dot(feature_mat)\n",
    "    return normed\n",
    "\n",
    "\n",
    "def hr(test_filter, test_triples, a, b, c,\n",
    "       how_many=[1, 3, 10], iter_show=False, freq=3000):\n",
    "    \"\"\" Calculate HR@[how_many] and MRR using filter \"\"\"\n",
    "    \n",
    "    #a = normalize_features(a)\n",
    "    #b = normalize_features(b)\n",
    "    #c = normalize_features(c)\n",
    "    total = len(test_triples)\n",
    "    hit = [0, 0, 0, 0]\n",
    "    iteration = 0\n",
    "    for entity, filt in zip(test_triples, test_filter):\n",
    "        p = entity[0]\n",
    "        q = entity[1]\n",
    "        r = entity[2]\n",
    "\n",
    "        candidate_values = np.sum(a[p, :] * b[q, :] * c, axis=1)\n",
    "        candidate_values = sigmoid(candidate_values)\n",
    "        \n",
    "        top = np.argsort(candidate_values)[::-1]\n",
    "        top = list(top)\n",
    "        \n",
    "        for obj in filt:\n",
    "            top.remove(obj)\n",
    "        \n",
    "        ind = top.index(r)\n",
    "        for i, h in enumerate(how_many):\n",
    "            if ind < h:\n",
    "                hit[i] += 1\n",
    "        hit[3] += 1 / (1 + ind)    \n",
    "        \n",
    "        iteration += 1\n",
    "        if iter_show:\n",
    "            if iteration % freq == 0:\n",
    "                print(hit[2] / iteration, hit[2], iteration)\n",
    "            \n",
    "    return hit[0] / total, hit[1] / total, hit[2] / total, hit[3] / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('/notebook/Relations_Learning/results/gpu_a.npz.npy')\n",
    "b = np.load('/notebook/Relations_Learning/results/gpu_b.npz.npy')\n",
    "c = np.load('/notebook/Relations_Learning/results/gpu_c.npz.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14541, 200)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 s, sys: 172 ms, total: 11.5 s\n",
      "Wall time: 11.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 0.001, 0.0006409431810042658)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "hr(valid_filter[:1000], valid_triples[:1000], a, b, c, [1, 3, 10])  #[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hr(valid_filter[:1000], valid_triples[:1000], a, b, c, [1, 3, 10])  #[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/notebook/Relations_Learning/gpu/general_functions1.py\u001b[0m in \u001b[0;36mhr\u001b[0;34m(test_filter, test_triples, a, b, c, how_many, iter_show, freq)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mcandidate_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mcandidate_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2248\u001b[0;31m                           initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hr(valid_filter, valid_triples, a, b, c, [1, 3, 10])  #[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hr(test_filter, test_triples, a, b, c, [1, 3, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable, Function\n",
    "import random\n",
    "\n",
    "import math\n",
    "\n",
    "class WARP(Function): \n",
    "    '''\n",
    "    autograd function of WARP loss\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def forward(input, target, max_num_trials = None):\n",
    "        \n",
    "        batch_size = target.size()[0]\n",
    "        \n",
    "        if max_num_trials is None: \n",
    "            max_num_trials = target.size()[1] - 1\n",
    "        \n",
    "        positive_indices = torch.zeros(input.size())\n",
    "        negative_indices = torch.zeros(input.size())\n",
    "        L = torch.zeros(input.size()[0])\n",
    "        \n",
    "        all_labels_idx = np.arange(target.size()[1])\n",
    "        \n",
    "        Y = float(target.size()[1])\n",
    "        J = torch.nonzero(target)\n",
    "\n",
    "        for i in range(batch_size): \n",
    "            \n",
    "            msk = np.ones(target.size()[1], dtype = bool)\n",
    "            \n",
    "            # Find the positive label for this example\n",
    "            j = J[i, 1]\n",
    "            positive_indices[i, j] = 1\n",
    "            msk[j] = False\n",
    "            \n",
    "            # initialize the sample_score_margin\n",
    "            sample_score_margin = -1\n",
    "            num_trials = 0\n",
    "            \n",
    "            neg_labels_idx = all_labels_idx[msk]\n",
    "\n",
    "            while ((sample_score_margin < 0) and (num_trials < max_num_trials)):\n",
    "                 \n",
    "                #randomly sample a negative label\n",
    "                neg_idx = random.sample(list(neg_labels_idx), 1)[0]\n",
    "                msk[neg_idx] = False\n",
    "                neg_labels_idx = all_labels_idx[msk]\n",
    "                \n",
    "                num_trials += 1\n",
    "                # calculate the score margin \n",
    "                sample_score_margin = 1 + input[i, neg_idx] - input[i, j] \n",
    "            \n",
    "            if sample_score_margin < 0:\n",
    "                # checks if no violating examples have been found \n",
    "                continue\n",
    "            else: \n",
    "                loss_weight = np.log(math.floor((Y-1)/(num_trials)))\n",
    "                L[i] = loss_weight\n",
    "                negative_indices[i, neg_idx] = 1\n",
    "                \n",
    "        loss = L * (1-torch.sum(positive_indices*input, dim = 1) + torch.sum(negative_indices*input, dim = 1))\n",
    "        \n",
    "        # ctx.save_for_backward(input, target)\n",
    "        # ctx.L = L\n",
    "        # ctx.positive_indices = positive_indices\n",
    "        # ctx.negative_indices = negative_indices\n",
    "        \n",
    "        return torch.sum(loss , dim = 0, keepdim = True)\n",
    "\n",
    "    # This function has only a single output, so it gets only one gradient \n",
    "    @staticmethod\n",
    "    def backward(input, target, grad_output):\n",
    "        #input, target = ctx.saved_variables\n",
    "        L = Variable(torch.unsqueeze(ctx.L, 1), requires_grad = False)\n",
    "\n",
    "        positive_indices = Variable(ctx.positive_indices, requires_grad = False) \n",
    "        negative_indices = Variable(ctx.negative_indices, requires_grad = False)\n",
    "        grad_input = grad_output*L*(negative_indices - positive_indices)\n",
    "\n",
    "        return grad_input, None, None    \n",
    "\n",
    "      \n",
    "class WARPLoss(nn.Module): \n",
    "    def __init__(self, max_num_trials = None): \n",
    "        super(WARPLoss, self).__init__()\n",
    "        self.max_num_trials = max_num_trials\n",
    "        \n",
    "    def forward(self, input, target): \n",
    "        return WARP.apply(input, target, self.max_num_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('/notebook/Relations_Learning/a200.npz.npy')\n",
    "b = np.load('/notebook/Relations_Learning/b200.npz.npy')\n",
    "c = np.load('/notebook/Relations_Learning/c200.npz.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_warp = 0.001\n",
    "epoch =0\n",
    "\n",
    "wp = WARP()\n",
    "while (epoch < 1):\n",
    "    print (\"warp loss!\")\n",
    "    a_torch = torch.tensor(a, requires_grad=True)\n",
    "    b_torch = torch.tensor(b, requires_grad=True)\n",
    "    c_torch = torch.tensor(c, requires_grad=True)\n",
    "    list_of_inputs = []\n",
    "    list_of_targets = []\n",
    "    for entity, filt in zip(test_triples, test_filter):\n",
    "        p = entity[0]\n",
    "        q = entity[1]\n",
    "        r = entity[2]\n",
    "\n",
    "        candidate_values = torch.sum(a_torch[p, :] * b_torch[q, :] * c_torch, axis=1)\n",
    "\n",
    "        for obj in filt:\n",
    "            idxs = (candidate_values == obj).nonzero(as_tuple=False)\n",
    "            candidate_values[idxs] = 0.0\n",
    "            \n",
    "        candidate_values = torch.sigmoid(candidate_values)\n",
    "\n",
    "        target = torch.zeros(len(candidate_values))\n",
    "        target[r] = 1.0\n",
    "        list_of_inputs.append(candidate_values)\n",
    "        list_of_targets.append(target)\n",
    "\n",
    "    inputs = torch.stack(list_of_inputs)\n",
    "    print (list_of_inputs[0].shape, inputs.shape) #should be batch_size*\n",
    "    targets = torch.stack(list_of_targets)\n",
    "    print (list_of_targets[0].shape, targets.shape) #should be batch_size*\n",
    "    \n",
    "    #batch_size = 16\n",
    "    #for i in range(inputs.shape[0]//batch_size):\n",
    "        #print (i)\n",
    "        #end = min(inputs.shape[0] - 1, (i+1)*batch_size)\n",
    "    loss = wp.forward(inputs, targets) \n",
    "    print (\"warp loss is counted\", loss)\n",
    "\n",
    "        #if (i ==0):\n",
    "    loss.backward()\n",
    "    \n",
    "\n",
    "    a = a - lr_warp*a_torch.grad.data.numpy()\n",
    "    b = b - lr_warp*b_torch.grad.data.numpy()\n",
    "    c = c - lr_warp*c_torch.grad.data.numpy()\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"HR@10\")\n",
    "plt.title(f\"FB15k-237 / GCP-GD3(R={rank}) G\")\n",
    "plt.plot(np.arange(1, it+1), hr_arr[:it, 2], '-*', c=\"#8b0a50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@jit(nopython=True)\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "#@jit(nopython=True)\n",
    "def hr(test_filter, test_triples, a, b, c,\n",
    "       how_many=[1, 3, 10], iter_show=False, freq=3000):\n",
    "    \"\"\" Calculate HR@[how_many] and MRR using filter \"\"\"\n",
    "    \n",
    "    total = len(test_triples)\n",
    "    hit = [0, 0, 0, 0]\n",
    "    iteration = 0\n",
    "    for entity, filt in zip(test_triples, test_filter):\n",
    "        p = entity[0]\n",
    "        q = entity[1]\n",
    "        r = entity[2]\n",
    "\n",
    "        candidate_values = np.sum(a[p, :] * b[q, :] * c, axis=1)\n",
    "        candidate_values = sigmoid(candidate_values)\n",
    "        \n",
    "        top = np.argsort(candidate_values)[::-1]\n",
    "        top = list(top)\n",
    "        \n",
    "        for obj in filt:\n",
    "            top.remove(obj)\n",
    "        \n",
    "        ind = top.index(r)\n",
    "        for i, h in enumerate(how_many):\n",
    "            if ind < h:\n",
    "                hit[i] += 1\n",
    "        hit[3] += 1 / (1 + ind)    \n",
    "        \n",
    "        iteration += 1\n",
    "        if iter_show:\n",
    "            if iteration % freq == 0:\n",
    "                print(hit[2] / iteration, hit[2], iteration)\n",
    "            \n",
    "    return hit[0] / total, hit[1] / total, hit[2] / total, hit[3] / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('/notebook/wikidata_tensor/embeddings_tucker_als/embedding_size_variation/200/u0_200_237.npz.npy')\n",
    "b = np.load('/notebook/wikidata_tensor/embeddings_tucker_als/embedding_size_variation/200/u1_200_237.npz.npy')\n",
    "c = np.load('/notebook/wikidata_tensor/embeddings_tucker_als/embedding_size_variation/200/u2_200_237.npz.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "shape = (100, 100, 100)\n",
    "coo, vals = gen_coo_tensor(init_shape, density=0.02)\n",
    "assert check_coo_tensor(coo)!= \"Bad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 20\n",
    "rank = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "a, b, c, err, it = gcp_gd(\n",
    "    coo, vals, shape,\n",
    "    bernoulli_logit_loss,\n",
    "    bernoulli_logit_loss_grad,\n",
    "    rank=rank,\n",
    "    lr=0.1,\n",
    "    l2=0,\n",
    "    max_iter=max_iter,\n",
    "    tol=1e-8,\n",
    "    seed=13,\n",
    "    show_iter=False,\n",
    "    it_over=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Relative error\")\n",
    "plt.title(f\"Random tensor / CP-ALS3(R={rank})\")\n",
    "#plt.xticks(np.arange(max_iter))\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(np.arange(max_iter), err[:max_iter], 'g-*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CP-ALS3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "max_iter = 20\n",
    "rank = 3\n",
    "a, b, c, err, it = cp.cp_als3(coo, vals, shape, rank=rank, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Relative error\")\n",
    "plt.title(f\"Random tensor / CP-ALS3(R={rank})\")\n",
    "#plt.xticks(np.arange(max_iter))\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(np.arange(max_iter), err[:max_iter], 'g-*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
